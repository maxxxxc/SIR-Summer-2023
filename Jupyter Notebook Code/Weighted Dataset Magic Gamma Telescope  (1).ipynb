{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0ddd4b",
   "metadata": {},
   "source": [
    "# Magic Gamma Telescope\n",
    "\n",
    "Dataset is from https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\n",
    "\n",
    "n = 19020\n",
    "\n",
    "10 features\n",
    "\n",
    "- X1.  fLength:  continuous  # major axis of ellipse [mm]\n",
    "- X2.  fWidth:   continuous  # minor axis of ellipse [mm] \n",
    "- X3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\n",
    "- X4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\n",
    "- X5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\n",
    "- X6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\n",
    "- X7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \n",
    "- X8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\n",
    "- X9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\n",
    "- X10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\n",
    "- Y.  class:    g,h         # gamma (signal), hadron (background)\n",
    "  - g = gamma (signal):     12332\n",
    "  - h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "961a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b861a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/magic04.data\"\n",
    "column_names = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \"Y\"]\n",
    "df = pd.read_csv(url, header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9658e176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19020, 11)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c99a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2      X3      X4      X5        X6       X7       X8  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
      "\n",
      "        X9       X10  Y  \n",
      "0  40.0920   81.8828  g  \n",
      "1   6.3609  205.2610  g  \n",
      "2  76.9600  256.7880  g  \n",
      "3  10.4490  116.7370  g  \n",
      "4   4.6480  356.4620  g  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4330eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ff409132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Y\", axis=1)\n",
    "y = df[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c6d4ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    12332\n",
       "h     6688\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "54794e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12332\n",
       "0     6688\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.replace({'g' : 1, 'h' : 0})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d8a20",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9b2ba396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.790571328426218\n",
      "Test Accuracy: 0.7879863301787592\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "#model = LogisticRegression()\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a20454",
   "metadata": {},
   "source": [
    "# Divide and Conquer\n",
    "\n",
    "Divide the training data into 11 batches, train a logistic model on each of the batch, and then combine the 11 prediction results. Consider the following two ensemble methods:\n",
    "- majority voting\n",
    "- average (or sum) of the logit output and then make decision based on its sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "806458ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "    \n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    #indices = np.random.permutation(len(X))\n",
    "    \n",
    "    #change 7/12\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    \n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_logit = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "    \n",
    "    preds_voting_weighted = preds_voting\n",
    "    preds_logit_weighted = preds_logit\n",
    "    preds_prob_weighted = preds_prob\n",
    "    \n",
    "    total_cverr = 0\n",
    "    \n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        \n",
    "        # Create a logistic regression model\n",
    "        model = LogisticRegression(max_iter=500)\n",
    "        \n",
    "        # Select the current batch for training\n",
    "        #X_batch = X_train[start_index:end_index]\n",
    "        #y_batch = y_train[start_index:end_index]\n",
    "        \n",
    "        #change 7/12\n",
    "        X_batch = X_train.iloc[indices[start_index:end_index]]\n",
    "        y_batch = y_train.iloc[indices[start_index:end_index]]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model on the current batch\n",
    "        model.fit(X_batch_scaled, y_batch)\n",
    "        current_cverr = cross_val_score(model, X_batch_scaled, y_batch, cv = 5, scoring = 'accuracy').mean()\n",
    "        total_cverr += current_cverr\n",
    "               \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Accumulate the predictions using majority voting\n",
    "        preds_voting += (y_pred == 1)\n",
    "        preds_voting_weighted += (y_pred == 1) * current_cverr\n",
    "    \n",
    "        # Accumulate the predictions using logit\n",
    "        y_pred = model.decision_function(X_test_scaled)\n",
    "        preds_logit += y_pred\n",
    "        preds_logit_weighted += y_pred * current_cverr\n",
    "        \n",
    "        #Accumulate the probs\n",
    "        y_pred = model.predict_proba(X_test_scaled)\n",
    "        preds_prob += y_pred[:,1]\n",
    "        preds_prob_weighted += y_pred[:,1] * current_cverr\n",
    "    \n",
    "    accuracy = np.zeros(7)\n",
    "    \n",
    "    preds_voting_weighted = preds_voting_weighted / total_cverr * num_batches\n",
    "    preds_logit_weighted = preds_logit_weighted / total_cverr * num_batches\n",
    "    preds_prob_weighted = preds_prob_weighted / total_cverr * num_batches\n",
    "    \n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 1, 0)\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    final_predictions = np.where(preds_voting_weighted > num_batches / 2, 1, 0)\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_logit > 0, 1, 0)\n",
    "    accuracy[2] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    final_predictions = np.where(preds_logit_weighted > 0, 1, 0)\n",
    "    accuracy[3] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    #Average of probs\n",
    "    final_predictions = np.where(preds_prob / num_batches > 0.5, 1, 0)\n",
    "    accuracy[4] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    final_predictions = np.where(preds_prob_weighted / num_batches > 0.5, 1, 0)\n",
    "    accuracy[5] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    # Train a model on all 11 batches of training data\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy[6] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273e621",
   "metadata": {},
   "source": [
    "Try the divide and conquer approaches 10 times, reporting the following error matrix. \n",
    "- 10-by-4\n",
    "- col_1: majority voting\n",
    "- col_2: average the logit\n",
    "- col_3: average probabilities\n",
    "- col_4: using the model trained on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "67dade4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.78785489 0.78522608 0.78890641 0.78890641 0.7584122  0.74487382\n",
      "  0.78890641]\n",
      " [0.78299159 0.7820715  0.78548896 0.78548896 0.75394322 0.73961619\n",
      "  0.78588328]\n",
      " [0.78772345 0.78601472 0.78956362 0.78956362 0.76169821 0.74973712\n",
      "  0.78930074]\n",
      " [0.78956362 0.78732913 0.79035226 0.79035226 0.75946372 0.74737119\n",
      "  0.79035226]\n",
      " [0.79547844 0.79337539 0.79994742 0.79994742 0.76209253 0.74881703\n",
      "  0.80007886]\n",
      " [0.78180862 0.77852261 0.78325447 0.78325447 0.74907992 0.7360673\n",
      "  0.78299159]\n",
      " [0.78798633 0.78680336 0.79087802 0.79087802 0.75801788 0.74487382\n",
      "  0.79166667]\n",
      " [0.78601472 0.78522608 0.78732913 0.78732913 0.76209253 0.75118297\n",
      "  0.78732913]\n",
      " [0.79061514 0.78719769 0.79035226 0.79035226 0.75814932 0.74631966\n",
      "  0.79061514]\n",
      " [0.79008938 0.78864353 0.79324395 0.79324395 0.76274974 0.74881703\n",
      "  0.79271819]\n",
      " [0.78956362 0.78798633 0.78969506 0.78969506 0.75814932 0.74553102\n",
      "  0.78969506]\n",
      " [0.79271819 0.7904837  0.79376972 0.79376972 0.76038381 0.74434805\n",
      "  0.79337539]\n",
      " [0.79192955 0.79153523 0.79416404 0.79416404 0.76590431 0.75328601\n",
      "  0.79390116]\n",
      " [0.78535752 0.78443743 0.78588328 0.78588328 0.7555205  0.74250789\n",
      "  0.78548896]\n",
      " [0.7856204  0.78364879 0.78772345 0.78772345 0.7632755  0.75197161\n",
      "  0.78759201]\n",
      " [0.78877497 0.78798633 0.79232387 0.79232387 0.76012093 0.74750263\n",
      "  0.79206099]\n",
      " [0.79337539 0.78943218 0.79679285 0.79679285 0.76301262 0.74566246\n",
      "  0.79600421]\n",
      " [0.79508412 0.79337539 0.79731861 0.79731861 0.76130389 0.74723975\n",
      "  0.79784437]\n",
      " [0.78798633 0.78614616 0.78969506 0.78969506 0.75775499 0.7493428\n",
      "  0.78930074]\n",
      " [0.7820715  0.78154574 0.78286015 0.78286015 0.75998948 0.74973712\n",
      "  0.78312303]\n",
      " [0.79074658 0.78824921 0.79192955 0.79192955 0.76353838 0.74921136\n",
      "  0.79140379]\n",
      " [0.78680336 0.78404311 0.7862776  0.7862776  0.75854364 0.75\n",
      "  0.78614616]\n",
      " [0.78824921 0.78706625 0.79127234 0.79127234 0.75867508 0.74553102\n",
      "  0.79179811]\n",
      " [0.7911409  0.78943218 0.79219243 0.79219243 0.76064669 0.74789695\n",
      "  0.79311251]\n",
      " [0.79337539 0.78995794 0.79153523 0.79153523 0.75959516 0.74829127\n",
      "  0.79166667]\n",
      " [0.78811777 0.78535752 0.79022082 0.79022082 0.75985804 0.75052576\n",
      "  0.79022082]\n",
      " [0.79008938 0.78732913 0.79087802 0.79087802 0.76182965 0.74658254\n",
      "  0.79140379]\n",
      " [0.79100946 0.78995794 0.79232387 0.79232387 0.76550999 0.75302313\n",
      "  0.79311251]\n",
      " [0.79482124 0.79179811 0.79442692 0.79442692 0.76419558 0.75118297\n",
      "  0.79482124]\n",
      " [0.79350683 0.79127234 0.79521556 0.79521556 0.76274974 0.74907992\n",
      "  0.79521556]\n",
      " [0.79350683 0.79179811 0.7946898  0.7946898  0.76787592 0.75276025\n",
      "  0.79482124]\n",
      " [0.7849632  0.78062566 0.7849632  0.7849632  0.76117245 0.74842271\n",
      "  0.78509464]\n",
      " [0.79416404 0.79140379 0.79574132 0.79574132 0.76051525 0.74842271\n",
      "  0.79639853]\n",
      " [0.78575184 0.78364879 0.78903785 0.78903785 0.75630915 0.74671399\n",
      "  0.78969506]\n",
      " [0.7946898  0.79192955 0.7995531  0.7995531  0.76130389 0.74605678\n",
      "  0.80047319]\n",
      " [0.7820715  0.7807571  0.78456887 0.78456887 0.75736067 0.74382229\n",
      "  0.78456887]\n",
      " [0.79022082 0.78772345 0.79008938 0.79008938 0.76051525 0.75026288\n",
      "  0.79035226]\n",
      " [0.79192955 0.79008938 0.79245531 0.79245531 0.76051525 0.74658254\n",
      "  0.79245531]\n",
      " [0.78575184 0.7814143  0.78548896 0.78548896 0.7506572  0.73843323\n",
      "  0.78509464]\n",
      " [0.78956362 0.78759201 0.79061514 0.79061514 0.76077813 0.74842271\n",
      "  0.79100946]\n",
      " [0.78746057 0.7856204  0.78864353 0.78864353 0.75920084 0.7444795\n",
      "  0.7904837 ]\n",
      " [0.78470032 0.78220294 0.78930074 0.78930074 0.75170873 0.74132492\n",
      "  0.78930074]\n",
      " [0.78759201 0.78667192 0.79074658 0.79074658 0.76182965 0.74592534\n",
      "  0.79035226]\n",
      " [0.78995794 0.78851209 0.79166667 0.79166667 0.7584122  0.74474238\n",
      "  0.79271819]\n",
      " [0.78719769 0.78456887 0.79153523 0.79153523 0.75814932 0.74277077\n",
      "  0.79206099]\n",
      " [0.78824921 0.78824921 0.78864353 0.78864353 0.76077813 0.75092008\n",
      "  0.78864353]\n",
      " [0.78890641 0.78772345 0.7911409  0.7911409  0.75630915 0.74566246\n",
      "  0.7904837 ]\n",
      " [0.79035226 0.78667192 0.79429548 0.79429548 0.76209253 0.74566246\n",
      "  0.79455836]\n",
      " [0.7904837  0.78838065 0.79127234 0.79127234 0.7626183  0.75131441\n",
      "  0.79179811]\n",
      " [0.79061514 0.78956362 0.79219243 0.79219243 0.75736067 0.74592534\n",
      "  0.79140379]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i] = iterate_process(X, y)\n",
    "    seed += 2\n",
    "    \n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "48cd063e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78917192, 0.78713197, 0.79084911, 0.79084911, 0.75983438,\n",
       "       0.74709516, 0.79097792])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "94d8e980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0034632 , 0.00345379, 0.00374956, 0.00374956, 0.00355062,\n",
       "       0.00360188, 0.00383604])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "593a0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    indices = np.random.permutation(len(X))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3f532a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "37f49c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78588328, 0.78194006, 0.7856204 , 0.7856204 , 0.75026288,\n",
       "       0.73633018, 0.78575184])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_process(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e0874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
