{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0ddd4b",
   "metadata": {},
   "source": [
    "# Magic Gamma Telescope\n",
    "\n",
    "Dataset is from https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\n",
    "\n",
    "n = 19020\n",
    "\n",
    "10 features\n",
    "\n",
    "- X1.  fLength:  continuous  # major axis of ellipse [mm]\n",
    "- X2.  fWidth:   continuous  # minor axis of ellipse [mm] \n",
    "- X3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\n",
    "- X4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\n",
    "- X5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\n",
    "- X6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\n",
    "- X7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \n",
    "- X8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\n",
    "- X9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\n",
    "- X10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\n",
    "- Y.  class:    g,h         # gamma (signal), hadron (background)\n",
    "  - g = gamma (signal):     12332\n",
    "  - h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b861a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/magic04.data\"\n",
    "column_names = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \"Y\"]\n",
    "df = pd.read_csv(url, header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9658e176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19020, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c99a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2      X3      X4      X5        X6       X7       X8  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
      "\n",
      "        X9       X10  Y  \n",
      "0  40.0920   81.8828  g  \n",
      "1   6.3609  205.2610  g  \n",
      "2  76.9600  256.7880  g  \n",
      "3  10.4490  116.7370  g  \n",
      "4   4.6480  356.4620  g  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4330eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff409132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Y\", axis=1)\n",
    "y = df[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c6d4ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    12332\n",
       "h     6688\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d8a20",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b2ba396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.790571328426218\n",
      "Test Accuracy: 0.7879863301787592\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "#model = LogisticRegression()\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a20454",
   "metadata": {},
   "source": [
    "# Divide and Conquer\n",
    "\n",
    "Divide the training data into 11 batches, train a logistic model on each of the batch, and then combine the 11 prediction results. Consider the following two ensemble methods:\n",
    "- majority voting\n",
    "- average (or sum) of the logit output and then make decision based on its sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "806458ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    \n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    indices = np.random.permutation(len(X))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    \n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_logit = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        \n",
    "        # Create a logistic regression model\n",
    "        model = LogisticRegression(max_iter=500)\n",
    "        \n",
    "        # Select the current batch for training\n",
    "        X_batch = X_train[start_index:end_index]\n",
    "        y_batch = y_train[start_index:end_index]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model on the current batch\n",
    "        model.fit(X_batch_scaled, y_batch)\n",
    "               \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Accumulate the predictions using majority voting\n",
    "        preds_voting += (y_pred == 'h')\n",
    "    \n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = model.decision_function(X_test_scaled)\n",
    "        preds_logit += y_pred\n",
    "   \n",
    "    \n",
    "    accuracy = np.zeros(3)\n",
    "    \n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 'h', 'g')\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_logit > 0, 'h', 'g')\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    # Train a model on all 11 batches of training data\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy[2] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273e621",
   "metadata": {},
   "source": [
    "Try the divide and conquer approaches 10 times, reporting the following error matrix. \n",
    "- 10-by-3\n",
    "- col_1: majority voting\n",
    "- col_2: average the logit\n",
    "- col_3: using the model trained on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67dade4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.79206099 0.79179811 0.79100946]\n",
      " [0.79035226 0.79100946 0.7904837 ]\n",
      " [0.7856204  0.78680336 0.78680336]\n",
      " [0.7904837  0.79271819 0.79271819]\n",
      " [0.78706625 0.78824921 0.78851209]\n",
      " [0.78995794 0.79061514 0.79100946]\n",
      " [0.7862776  0.78588328 0.78535752]\n",
      " [0.78404311 0.78430599 0.78456887]\n",
      " [0.78746057 0.78785489 0.78759201]\n",
      " [0.79298107 0.79153523 0.79245531]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 10\n",
    "\n",
    "# Initialize an empty matrix (10-by-3) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 3))\n",
    "\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    accuracies[i] = iterate_process(X, y)\n",
    "    \n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "593a0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    indices = np.random.permutation(len(X))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f532a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37f49c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79390116, 0.79337539, 0.79311251])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_process(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba311e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
