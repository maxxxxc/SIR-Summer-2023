{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the MNIST DATA (5 vs 8)\n",
    "\n",
    "## Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Load data \n",
    "- 70K images from 10 classes\n",
    "- Each image is 28-by-28, stored in a 784 vector\n",
    "- lable (y) takes 10 different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Extract features (pixel values) and target labels\n",
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "3      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "4      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   pixel781  pixel782  pixel783  pixel784  \n",
      "0       0.0       0.0       0.0       0.0  \n",
      "1       0.0       0.0       0.0       0.0  \n",
      "2       0.0       0.0       0.0       0.0  \n",
      "3       0.0       0.0       0.0       0.0  \n",
      "4       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    0\n",
      "2    4\n",
      "3    1\n",
      "4    9\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6903, 7877, 6990, 7141, 6824, 6313, 6876, 7293, 6825, 6958],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = np.bincount(y)\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 12 randomly selected images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data \n",
    "Filter the dataset to include only the digits 5 and 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_filter = (y == 5) | (y == 8)\n",
    "X = X[digit_filter]\n",
    "y = y[digit_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13138, 784)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 8], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n5 = np.count_nonzero(y == 5)\n",
    "n8 = np.count_nonzero(y == 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6313, 6825)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n5, n8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6825\n",
       "1    6313\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.replace({5 : 1, 8 : 0})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "60\\% training and 40\\% test\n",
    "\n",
    "Try two different Logistic regression models:\n",
    "- Logistic regression with all 784 features;\n",
    "- Losgitic regression with 100 top PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9747526008627252\n",
      "Test Accuracy: 0.9490106544901066\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "#model = LogisticRegression()\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.62493822  -4.52236797   4.89404422   5.94546226  12.81172949\n",
      "   0.48844461 -12.62286427   4.16760299  -1.66570542   7.58588442]\n",
      "[[9.70907044e-03 9.90290930e-01]\n",
      " [9.89253473e-01 1.07465269e-02]\n",
      " [7.43536680e-03 9.92564633e-01]\n",
      " [2.61085759e-03 9.97389142e-01]\n",
      " [2.72857185e-06 9.99997271e-01]\n",
      " [3.80260047e-01 6.19739953e-01]\n",
      " [9.99996704e-01 3.29578043e-06]\n",
      " [1.52530835e-02 9.84746916e-01]\n",
      " [8.41002401e-01 1.58997599e-01]\n",
      " [5.07308197e-04 9.99492692e-01]]\n",
      "[1 0 1 1 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_test_logits = model.decision_function(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)\n",
    "print(y_test_logits[:10])\n",
    "print(y_test_prob[:10])\n",
    "print(y_test_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9902909295571708, 0.009709070442829145)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1+ np.exp(-y_test_logits[0])), 1/(1+ np.exp(y_test_logits[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Logistic Regression: use top 100 PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9628266937325551\n",
      "Test Accuracy: 0.9619482496194824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Create and train the logistic regression model on the PCA-transformed data\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test_pca)\n",
    "y_train_pred = model.predict(X_train_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide and Conquer\n",
    "\n",
    "Divide the training data into 11 batches, train a logistic model on each of the batch, and then combine the 11 prediction results. Consider the following two ensemble methods:\n",
    "- majority voting\n",
    "- average (or sum) of the logit output and then make decision based on its sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting Accuracy: 0.0\n",
      "Average Logit Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Define the number of batches\n",
    "num_batches = 11\n",
    "\n",
    "# Calculate the batch size\n",
    "batch_size = len(X_train) // num_batches\n",
    "\n",
    "# Initialize an empty list to store the models\n",
    "models = []\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Split the training data into batches, fit a logistic regression model on each batch\n",
    "for i in range(num_batches):\n",
    "    # Calculate the starting and ending indices for the current batch\n",
    "    start_index = i * batch_size\n",
    "    end_index = (i + 1) * batch_size\n",
    "    \n",
    "    # Create a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    # Select the current batch for training\n",
    "    X_batch = X_train[start_index:end_index]\n",
    "    y_batch = y_train[start_index:end_index]\n",
    "    \n",
    "    # Fit the model on the current batch\n",
    "    model.fit(X_batch, y_batch)\n",
    "    \n",
    "    # Append the trained model to the list\n",
    "    models.append(model)\n",
    "\n",
    "# Make predictions on the test set using majority voting\n",
    "preds_voting = np.zeros(len(y_test))\n",
    "# Make predictions on the test set using average of logit\n",
    "preds_logit = np.zeros(len(y_test))\n",
    "\n",
    "for model in models:\n",
    "    # Make predictions using each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Accumulate the predictions using majority voting\n",
    "    preds_voting += (y_pred == 8)\n",
    "    \n",
    "    # Accumulate the predictions using majority voting\n",
    "    y_pred = model.decision_function(X_test)\n",
    "    preds_logit += y_pred\n",
    "    \n",
    "# Majority voting (selecting the most frequent prediction for each sample)\n",
    "final_predictions = np.where(preds_voting > len(models) / 2, 8, 5)\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(\"Majority Voting Accuracy:\", accuracy)\n",
    "\n",
    "# Average of logit\n",
    "final_predictions = np.where(preds_logit > 0, 8, 5)\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(\"Average Logit Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration Code\n",
    "\n",
    "We need to repeat the process above 100 times and record the corresponding accuracies. Let's write a function of the process above and then call this function 100 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    \n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    #indices = np.random.permutation(len(X))\n",
    "    \n",
    "    #change 7/12\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    \n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_logit = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        \n",
    "        # Create a logistic regression model\n",
    "        model = LogisticRegression(max_iter=500)\n",
    "        \n",
    "        # Select the current batch for training\n",
    "        X_batch = X_train.iloc[indices[start_index:end_index]]\n",
    "        y_batch = y_train.iloc[indices[start_index:end_index]]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model on the current batch\n",
    "        model.fit(X_batch_scaled, y_batch)\n",
    "               \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Accumulate the predictions using majority voting\n",
    "        preds_voting += (y_pred == 1)\n",
    "    \n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = model.decision_function(X_test_scaled)\n",
    "        preds_logit += y_pred\n",
    "        \n",
    "        #Accumulate the probs\n",
    "        y_pred = model.predict_proba(X_test_scaled)\n",
    "        preds_prob += y_pred[:,1]\n",
    "   \n",
    "    \n",
    "    accuracy = np.zeros(4)\n",
    "    \n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 1, 0)\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_logit > 0, 1, 0)\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    #Average of probs\n",
    "    final_predictions = np.where(preds_prob / num_batches > 0.5, 1, 0)\n",
    "    accuracy[2] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    # Train a model on all 11 batches of training data\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy[3] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.96860731 0.96194825 0.96860731 0.95547945]\n",
      " [0.96575342 0.9598554  0.96594368 0.95509893]\n",
      " [0.96099696 0.96023592 0.96270928 0.95091324]\n",
      " [0.96213851 0.9608067  0.96118721 0.94805936]\n",
      " [0.9608067  0.96061644 0.96004566 0.95262557]\n",
      " [0.96213851 0.96232877 0.96366058 0.95300609]\n",
      " [0.96194825 0.96061644 0.9630898  0.95376712]\n",
      " [0.96118721 0.9608067  0.96232877 0.95281583]\n",
      " [0.96594368 0.96575342 0.96765601 0.95471842]\n",
      " [0.96251903 0.96537291 0.96518265 0.94920091]\n",
      " [0.96689498 0.96461187 0.96708524 0.95566971]\n",
      " [0.96289954 0.96156773 0.96442161 0.95566971]\n",
      " [0.96232877 0.96004566 0.96156773 0.95072298]\n",
      " [0.9608067  0.95681126 0.95928463 0.94901065]\n",
      " [0.96232877 0.9630898  0.96328006 0.95509893]\n",
      " [0.96023592 0.95890411 0.96023592 0.95547945]\n",
      " [0.96270928 0.96251903 0.96328006 0.95490868]\n",
      " [0.9608067  0.96004566 0.96137747 0.9543379 ]\n",
      " [0.96423135 0.96366058 0.96442161 0.95300609]\n",
      " [0.96289954 0.96194825 0.96270928 0.95148402]\n",
      " [0.96251903 0.96366058 0.9640411  0.94843988]\n",
      " [0.96289954 0.9608067  0.96347032 0.95585997]\n",
      " [0.95490868 0.95605023 0.956621   0.94748858]\n",
      " [0.96347032 0.9640411  0.96461187 0.95509893]\n",
      " [0.96042618 0.95814307 0.96023592 0.9478691 ]\n",
      " [0.96270928 0.96175799 0.9630898  0.95319635]\n",
      " [0.9608067  0.96004566 0.96004566 0.94767884]\n",
      " [0.96137747 0.95947489 0.96175799 0.95376712]\n",
      " [0.95947489 0.9575723  0.95871385 0.94977169]\n",
      " [0.96232877 0.96213851 0.9640411  0.95643075]\n",
      " [0.96328006 0.96118721 0.96328006 0.9543379 ]\n",
      " [0.96461187 0.96385084 0.96499239 0.9543379 ]\n",
      " [0.96156773 0.9608067  0.96156773 0.95414764]\n",
      " [0.96765601 0.9663242  0.96765601 0.95833333]\n",
      " [0.96499239 0.96423135 0.96613394 0.95262557]\n",
      " [0.96385084 0.96137747 0.96537291 0.95338661]\n",
      " [0.95833333 0.9575723  0.95909437 0.94996195]\n",
      " [0.96423135 0.96099696 0.96385084 0.95414764]\n",
      " [0.96289954 0.96289954 0.96270928 0.956621  ]\n",
      " [0.96442161 0.96156773 0.96442161 0.95015221]\n",
      " [0.95814307 0.95776256 0.95852359 0.94691781]\n",
      " [0.96175799 0.96213851 0.96156773 0.94996195]\n",
      " [0.9598554  0.95947489 0.96042618 0.95072298]\n",
      " [0.96213851 0.96156773 0.96270928 0.94863014]\n",
      " [0.96537291 0.96480213 0.96689498 0.95966514]\n",
      " [0.96194825 0.96194825 0.96213851 0.95186454]\n",
      " [0.96328006 0.96366058 0.9640411  0.95034247]\n",
      " [0.96537291 0.96251903 0.96347032 0.95243531]\n",
      " [0.96594368 0.96803653 0.96765601 0.95681126]\n",
      " [0.96137747 0.95490868 0.96023592 0.95091324]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty vector to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 4))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i] = iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96260274, 0.96145738, 0.96302892, 0.95265982])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00244367, 0.00261703, 0.00262762, 0.00301467])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13138"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13138"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13138, 784)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
