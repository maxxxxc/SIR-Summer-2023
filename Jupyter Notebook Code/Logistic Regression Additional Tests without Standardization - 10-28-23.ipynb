{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0ddd4b",
   "metadata": {},
   "source": [
    "# Magic Gamma Telescope\n",
    "\n",
    "Dataset is from https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\n",
    "\n",
    "n = 19020\n",
    "\n",
    "10 features\n",
    "\n",
    "- X1.  fLength:  continuous  # major axis of ellipse [mm]\n",
    "- X2.  fWidth:   continuous  # minor axis of ellipse [mm] \n",
    "- X3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\n",
    "- X4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\n",
    "- X5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\n",
    "- X6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\n",
    "- X7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \n",
    "- X8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\n",
    "- X9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\n",
    "- X10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\n",
    "- Y.  class:    g,h         # gamma (signal), hadron (background)\n",
    "  - g = gamma (signal):     12332\n",
    "  - h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "961a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b861a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/magic04.data\"\n",
    "column_names = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \"Y\"]\n",
    "df = pd.read_csv(url, header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4330eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff409132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Y\", axis=1)\n",
    "y = df[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28cccefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12332\n",
       "0     6688\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.replace({'g' : 1, 'h' : 0})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a20454",
   "metadata": {},
   "source": [
    "# Divide and Conquer\n",
    "\n",
    "Divide the training data into 11 batches, train a logistic model on each of the batch, and then combine the 11 prediction results. Consider the following two ensemble methods:\n",
    "- majority voting\n",
    "- average (or sum) of the logit output and then make decision based on its sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "806458ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    \n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    #indices = np.random.permutation(len(X))\n",
    "    \n",
    "    #change 7/12\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    \n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_logit = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "    \n",
    "    preds_voting_weighted = np.zeros(len(y_test))\n",
    "    preds_logit_weighted = np.zeros(len(y_test))\n",
    "    preds_prob_weighted = np.zeros(len(y_test))\n",
    "    \n",
    "    total_cverr = 0\n",
    "    \n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        \n",
    "        # Select the current batch for training\n",
    "        #X_batch = X_train[start_index:end_index]\n",
    "        #y_batch = y_train[start_index:end_index]\n",
    "        \n",
    "        #change 7/12\n",
    "        X_batch = X_train.iloc[indices[start_index:end_index]]\n",
    "        y_batch = y_train.iloc[indices[start_index:end_index]]\n",
    "        \n",
    "        #scaler = StandardScaler()\n",
    "        X_batch_scaled = X_batch\n",
    "        X_test_scaled = X_test\n",
    "        \n",
    "        # Fit the model on the current batch\n",
    "        model = sm.GLM(family = sm.families.Binomial())\n",
    "        model.fit(y_batch, X_batch_scaled)\n",
    "        current_cverr = cross_val_score(model, X_batch_scaled, y_batch, cv = 5, scoring = 'accuracy').mean()\n",
    "        total_cverr += current_cverr\n",
    "               \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Accumulate the predictions using majority voting\n",
    "        preds_voting += (y_pred == 1)\n",
    "        preds_voting_weighted += (y_pred == 1) * current_cverr\n",
    "    \n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = model.decision_function(X_test_scaled)\n",
    "        preds_logit += y_pred\n",
    "        preds_logit_weighted += y_pred * current_cverr\n",
    "        \n",
    "        #Accumulate the probs\n",
    "        y_pred = model.predict_proba(X_test_scaled)\n",
    "        preds_prob += y_pred[:,1]\n",
    "        preds_prob_weighted += y_pred[:,1] * current_cverr\n",
    "    \n",
    "    accuracy = np.zeros(7)\n",
    "    auc_accuracy = np.zeros(7)\n",
    "    \n",
    "    preds_voting_weighted = preds_voting_weighted / total_cverr * num_batches\n",
    "    preds_logit_weighted = preds_logit_weighted / total_cverr * num_batches\n",
    "    preds_prob_weighted = preds_prob_weighted / total_cverr * num_batches\n",
    "    \n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 1, 0)\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[0] = roc_auc_score(y_test, preds_voting)\n",
    "    \n",
    "    final_predictions = np.where(preds_voting_weighted > num_batches / 2, 1, 0)\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[1] = roc_auc_score(y_test, preds_voting_weighted)\n",
    "    \n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_logit > 0, 1, 0)\n",
    "    accuracy[2] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[2] = roc_auc_score(y_test, preds_logit)\n",
    "    \n",
    "    final_predictions = np.where(preds_logit_weighted > 0, 1, 0)\n",
    "    accuracy[3] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[3] = roc_auc_score(y_test, preds_logit_weighted)\n",
    "    \n",
    "    #Average of probs\n",
    "    final_predictions = np.where(preds_prob / num_batches > 0.5, 1, 0)\n",
    "    accuracy[4] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[4] = roc_auc_score(y_test, preds_prob)\n",
    "    \n",
    "    final_predictions = np.where(preds_prob_weighted / num_batches > 0.5, 1, 0)\n",
    "    accuracy[5] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[5] = roc_auc_score(y_test, preds_prob_weighted)\n",
    "    \n",
    "    # Train a model on all 11 batches of training data\n",
    "    model = sm.GLM(family = sm.families.Binomial())\n",
    "    \n",
    "    #scaler = StandardScaler()\n",
    "    X_train_scaled = X_train\n",
    "    X_test_scaled = X_test\n",
    "    #model.fit(X_train_scaled, y_train)\n",
    "    model.fit(y_train, X_train_scaled)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy[6] = accuracy_score(y_test, y_pred)\n",
    "    y_pred = model.decision_function(X_test_scaled)\n",
    "    auc_accuracy[6] = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, auc_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273e621",
   "metadata": {},
   "source": [
    "Try the divide and conquer approaches 10 times, reporting the following error matrix. \n",
    "- 10-by-4\n",
    "- col_1: majority voting\n",
    "- col_2: average the logit\n",
    "- col_3: average probabilities\n",
    "- col_4: using the model trained on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67dade4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GLM.__init__() missing 2 required positional arguments: 'endog' and 'exog'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_repeats):\n\u001b[0;32m     11\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m---> 12\u001b[0m     accuracies[i], auc_accuracies[i] \u001b[38;5;241m=\u001b[39m iterate_process(X, y)\n\u001b[0;32m     13\u001b[0m     seed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Print the accuracies\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 49\u001b[0m, in \u001b[0;36miterate_process\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     46\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m X_test\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Fit the model on the current batch\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mGLM(family \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mfamilies\u001b[38;5;241m.\u001b[39mBinomial())\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(y_batch, X_batch_scaled)\n\u001b[0;32m     51\u001b[0m current_cverr \u001b[38;5;241m=\u001b[39m cross_val_score(model, X_batch_scaled, y_batch, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mTypeError\u001b[0m: GLM.__init__() missing 2 required positional arguments: 'endog' and 'exog'"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = iterate_process(X, y)\n",
    "    seed += 2\n",
    "    \n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9593cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd556ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a4909",
   "metadata": {},
   "source": [
    "# Wireless Indoor Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a931601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1    1000\n",
       "Name: 7, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/wifi_localization.txt\"\n",
    "df = pd.read_csv(url, sep = '\\t', header = None)\n",
    "\n",
    "X = df.drop(7, axis=1)\n",
    "y = df[7]\n",
    "\n",
    "y = y.replace({2 : 0, 1 : 0, 3: 1, 4 : 1})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d383e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.92875 0.92875 0.93    0.93    0.93    0.93    0.93375]\n",
      " [0.915   0.915   0.9175  0.9175  0.91875 0.9175  0.90625]\n",
      " [0.9275  0.9275  0.93125 0.93125 0.92875 0.9275  0.9325 ]\n",
      " [0.9175  0.9175  0.9175  0.9175  0.9175  0.9175  0.9175 ]\n",
      " [0.91    0.91    0.91875 0.91875 0.915   0.91375 0.92   ]\n",
      " [0.9225  0.9225  0.92125 0.9225  0.925   0.925   0.915  ]\n",
      " [0.9275  0.9275  0.925   0.92375 0.92375 0.92375 0.9225 ]\n",
      " [0.9175  0.9175  0.92125 0.92125 0.9225  0.9225  0.9225 ]\n",
      " [0.93625 0.93625 0.93875 0.93875 0.93875 0.93875 0.94   ]\n",
      " [0.92375 0.92375 0.92875 0.92875 0.925   0.92625 0.92125]\n",
      " [0.92375 0.92375 0.92375 0.9225  0.9225  0.9225  0.9225 ]\n",
      " [0.9175  0.9175  0.915   0.915   0.91625 0.91625 0.9175 ]\n",
      " [0.92    0.92    0.91875 0.91875 0.92125 0.92125 0.9275 ]\n",
      " [0.9325  0.9325  0.93875 0.93875 0.93875 0.93875 0.93   ]\n",
      " [0.93    0.93    0.93    0.93125 0.9325  0.9325  0.9275 ]\n",
      " [0.91375 0.91375 0.91375 0.91625 0.9125  0.9125  0.91375]\n",
      " [0.92625 0.92625 0.92125 0.92125 0.92    0.92    0.92125]\n",
      " [0.91625 0.91625 0.915   0.915   0.9175  0.9175  0.91625]\n",
      " [0.92375 0.92375 0.925   0.925   0.9275  0.9275  0.92625]\n",
      " [0.9275  0.9275  0.92625 0.925   0.92875 0.9275  0.92875]\n",
      " [0.935   0.935   0.925   0.925   0.9275  0.92625 0.93125]\n",
      " [0.9325  0.9325  0.93625 0.935   0.93375 0.935   0.93   ]\n",
      " [0.9175  0.9175  0.92125 0.9225  0.9225  0.92125 0.92   ]\n",
      " [0.92875 0.92875 0.93125 0.93125 0.93    0.93    0.93   ]\n",
      " [0.925   0.925   0.92    0.92125 0.92125 0.92125 0.92125]\n",
      " [0.925   0.925   0.93    0.93    0.9275  0.9275  0.92875]\n",
      " [0.9275  0.9275  0.9275  0.92625 0.9275  0.9275  0.93   ]\n",
      " [0.92375 0.92375 0.92625 0.92625 0.925   0.925   0.92875]\n",
      " [0.92625 0.92625 0.92625 0.92625 0.9275  0.9275  0.9225 ]\n",
      " [0.925   0.925   0.92875 0.9275  0.9275  0.9275  0.92375]\n",
      " [0.90875 0.90875 0.9175  0.9175  0.91375 0.91375 0.9175 ]\n",
      " [0.9175  0.9175  0.92    0.92    0.9175  0.9175  0.9175 ]\n",
      " [0.91375 0.91375 0.9125  0.9125  0.9125  0.9125  0.92125]\n",
      " [0.91875 0.91875 0.91875 0.9175  0.91875 0.91875 0.91625]\n",
      " [0.91375 0.91375 0.9175  0.9175  0.915   0.915   0.915  ]\n",
      " [0.91625 0.91625 0.92    0.92125 0.92    0.92    0.92   ]\n",
      " [0.91    0.91    0.915   0.91375 0.9125  0.91375 0.91125]\n",
      " [0.92375 0.92375 0.925   0.925   0.9225  0.9225  0.9225 ]\n",
      " [0.92875 0.92875 0.93125 0.93125 0.93125 0.93125 0.93125]\n",
      " [0.92625 0.92625 0.92625 0.92625 0.92625 0.92625 0.92375]\n",
      " [0.925   0.925   0.925   0.92375 0.92375 0.92375 0.92625]\n",
      " [0.9375  0.9375  0.93375 0.93375 0.93375 0.935   0.9325 ]\n",
      " [0.9225  0.9225  0.9275  0.92875 0.9225  0.9225  0.93   ]\n",
      " [0.93    0.93    0.9275  0.9275  0.92875 0.9275  0.92625]\n",
      " [0.93125 0.93125 0.9275  0.9275  0.9275  0.9275  0.9275 ]\n",
      " [0.92625 0.92625 0.92    0.92    0.925   0.925   0.92125]\n",
      " [0.91125 0.91125 0.9125  0.9125  0.9125  0.9125  0.91375]\n",
      " [0.92375 0.92375 0.9175  0.9175  0.91625 0.9175  0.9125 ]\n",
      " [0.9075  0.9075  0.905   0.905   0.9075  0.9075  0.9125 ]\n",
      " [0.92875 0.92875 0.9275  0.9275  0.92625 0.9275  0.9275 ]]\n",
      "AUC: [[0.97311099 0.97332662 0.98327406 0.98329906 0.98274903 0.98275528\n",
      "  0.98293029]\n",
      " [0.96205032 0.96173152 0.9776215  0.9776215  0.97887795 0.97891546\n",
      "  0.97783404]\n",
      " [0.97132843 0.97095916 0.98295102 0.98300735 0.98296354 0.98292599\n",
      "  0.98329526]\n",
      " [0.96114348 0.96115602 0.97828321 0.97825815 0.97932331 0.97934211\n",
      "  0.97909774]\n",
      " [0.96672625 0.96722628 0.97904257 0.97900507 0.97974261 0.97979261\n",
      "  0.97980511]\n",
      " [0.97096857 0.97121545 0.98172489 0.98171864 0.98146863 0.98147488\n",
      "  0.98209989]\n",
      " [0.96004714 0.9600659  0.97859344 0.97857469 0.9784559  0.97840589\n",
      "  0.97875599]\n",
      " [0.97185656 0.9714909  0.9819982  0.9820232  0.98277953 0.98277328\n",
      "  0.98232323]\n",
      " [0.97290762 0.97288257 0.98454638 0.98450253 0.9846654  0.98462155\n",
      "  0.98446495]\n",
      " [0.97211069 0.97216698 0.9831207  0.98312695 0.98339587 0.98338962\n",
      "  0.98327079]\n",
      " [0.97013437 0.9702875  0.98165625 0.9817     0.98144375 0.9814375\n",
      "  0.98183125]\n",
      " [0.97214509 0.97230769 0.97964353 0.97964978 0.9804753  0.98049406\n",
      "  0.98010632]\n",
      " [0.96901703 0.96902641 0.98000938 0.97997812 0.98007814 0.98011564\n",
      "  0.98057822]\n",
      " [0.9748185  0.97529062 0.98526129 0.98526754 0.98533633 0.98536134\n",
      "  0.98436083]\n",
      " [0.97512442 0.97508066 0.98141131 0.98139256 0.98215536 0.98213035\n",
      "  0.98218037]\n",
      " [0.959075   0.95925625 0.97595625 0.9759625  0.9756125  0.97560625\n",
      "  0.9757625 ]\n",
      " [0.97159048 0.97115914 0.98107074 0.98105824 0.98084569 0.98073316\n",
      "  0.98121452]\n",
      " [0.9625072  0.96208793 0.9750632  0.97504443 0.97521339 0.9751821\n",
      "  0.97545118]\n",
      " [0.96602361 0.96592046 0.97917656 0.97915156 0.9799955  0.97996424\n",
      "  0.97968293]\n",
      " [0.97460785 0.97438903 0.98280723 0.98281349 0.98420766 0.98420141\n",
      "  0.98276972]\n",
      " [0.96844572 0.96855836 0.97884909 0.97886786 0.97896173 0.97898676\n",
      "  0.97966884]\n",
      " [0.96797107 0.96770544 0.97918698 0.97918073 0.97939323 0.97936198\n",
      "  0.97995575]\n",
      " [0.96261878 0.96283803 0.97943485 0.9794787  0.97821961 0.97823214\n",
      "  0.9801427 ]\n",
      " [0.97126577 0.97111253 0.98095435 0.9808918  0.98185503 0.98178623\n",
      "  0.98223657]\n",
      " [0.96926702 0.96950766 0.9785988  0.97854879 0.97929259 0.97929259\n",
      "  0.97922383]\n",
      " [0.97009903 0.96990184 0.98307292 0.98306666 0.98337966 0.98339844\n",
      "  0.98258464]\n",
      " [0.97103053 0.97119928 0.98278707 0.98277457 0.98281207 0.98279332\n",
      "  0.98291832]\n",
      " [0.97033286 0.97058915 0.98204094 0.98206595 0.98215971 0.98214721\n",
      "  0.98197218]\n",
      " [0.96475509 0.96436689 0.97719631 0.97720257 0.97702726 0.97700847\n",
      "  0.97767217]\n",
      " [0.97417231 0.97394726 0.98219599 0.98218974 0.98253357 0.98253982\n",
      "  0.98338376]\n",
      " [0.96190664 0.96194415 0.97597789 0.97594038 0.97709709 0.97705957\n",
      "  0.97689701]\n",
      " [0.96223213 0.96186017 0.97792628 0.97787002 0.97741367 0.97739491\n",
      "  0.97787627]\n",
      " [0.96288434 0.96245912 0.97690706 0.97687579 0.97750736 0.97746359\n",
      "  0.97750736]\n",
      " [0.96714703 0.96724085 0.97930935 0.97927182 0.97882774 0.97877145\n",
      "  0.97946572]\n",
      " [0.96513737 0.96562531 0.97808027 0.97807402 0.97760484 0.97762987\n",
      "  0.97859323]\n",
      " [0.96268032 0.96263969 0.97913698 0.97908073 0.97941199 0.97936823\n",
      "  0.979862  ]\n",
      " [0.96695983 0.96672806 0.97961025 0.97958519 0.97944738 0.97947243\n",
      "  0.97945991]\n",
      " [0.96446013 0.96471026 0.9799461  0.97997111 0.98013995 0.98013369\n",
      "  0.98016496]\n",
      " [0.96484451 0.96502266 0.98110955 0.98107204 0.98022816 0.98024066\n",
      "  0.98071574]\n",
      " [0.97165131 0.97176393 0.98148044 0.9814867  0.98119263 0.98119889\n",
      "  0.98131777]\n",
      " [0.96966884 0.96978135 0.98311706 0.98308581 0.98307956 0.98309831\n",
      "  0.98292954]\n",
      " [0.97238326 0.97241146 0.98436942 0.98435688 0.98436942 0.98440075\n",
      "  0.98446343]\n",
      " [0.971219   0.97136276 0.98085434 0.98085434 0.98062306 0.98064806\n",
      "  0.98157941]\n",
      " [0.97365213 0.9737459  0.98322238 0.98320363 0.98417253 0.98416628\n",
      "  0.98315987]\n",
      " [0.97001888 0.97027515 0.9819732  0.9819732  0.98218572 0.98223572\n",
      "  0.98261701]\n",
      " [0.97511188 0.97524313 0.98078077 0.98078702 0.98163704 0.98164329\n",
      "  0.98086202]\n",
      " [0.95434866 0.95430486 0.97740113 0.97736359 0.97748247 0.97739487\n",
      "  0.97769519]\n",
      " [0.96829683 0.96799055 0.97763526 0.97756026 0.97767277 0.97764151\n",
      "  0.97791654]\n",
      " [0.96341662 0.96341349 0.97521509 0.97510879 0.97518382 0.97520258\n",
      "  0.97671569]\n",
      " [0.96412339 0.96397022 0.98307607 0.98310733 0.98175066 0.9817069\n",
      "  0.98363874]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = iterate_process(X, y)\n",
    "    seed += 2\n",
    "    \n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34e502b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9229  , 0.9229  , 0.92355 , 0.923525, 0.923325, 0.9233  ,\n",
       "       0.9231  ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d9d82f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00729486, 0.00729486, 0.00697029, 0.00688608, 0.00692193,\n",
       "       0.00695414, 0.00688858])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29295cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9679879 , 0.96798493, 0.98029316, 0.98028103, 0.98044895,\n",
       "       0.98044083, 0.98062023])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "980a4563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00481803, 0.00485437, 0.00250549, 0.00251837, 0.0025293 ,\n",
       "       0.00253446, 0.00233349])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec614f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b198a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
