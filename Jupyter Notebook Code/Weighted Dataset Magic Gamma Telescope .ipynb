{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0ddd4b",
   "metadata": {},
   "source": [
    "# Magic Gamma Telescope\n",
    "\n",
    "Dataset is from https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\n",
    "\n",
    "n = 19020\n",
    "\n",
    "10 features\n",
    "\n",
    "- X1.  fLength:  continuous  # major axis of ellipse [mm]\n",
    "- X2.  fWidth:   continuous  # minor axis of ellipse [mm] \n",
    "- X3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\n",
    "- X4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\n",
    "- X5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\n",
    "- X6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\n",
    "- X7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \n",
    "- X8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\n",
    "- X9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\n",
    "- X10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\n",
    "- Y.  class:    g,h         # gamma (signal), hadron (background)\n",
    "  - g = gamma (signal):     12332\n",
    "  - h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "961a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b861a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/magic04.data\"\n",
    "column_names = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \"Y\"]\n",
    "df = pd.read_csv(url, header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9658e176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19020, 11)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3c99a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2      X3      X4      X5        X6       X7       X8  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
      "\n",
      "        X9       X10  Y  \n",
      "0  40.0920   81.8828  g  \n",
      "1   6.3609  205.2610  g  \n",
      "2  76.9600  256.7880  g  \n",
      "3  10.4490  116.7370  g  \n",
      "4   4.6480  356.4620  g  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4330eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ff409132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Y\", axis=1)\n",
    "y = df[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9c6d4ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    12332\n",
       "h     6688\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "28cccefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12332\n",
       "0     6688\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.replace({'g' : 1, 'h' : 0})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d8a20",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9b2ba396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.790571328426218\n",
      "Test Accuracy: 0.7879863301787592\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "#model = LogisticRegression()\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a20454",
   "metadata": {},
   "source": [
    "# Divide and Conquer\n",
    "\n",
    "Divide the training data into 11 batches, train a logistic model on each of the batch, and then combine the 11 prediction results. Consider the following two ensemble methods:\n",
    "- majority voting\n",
    "- average (or sum) of the logit output and then make decision based on its sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "806458ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    \n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    #indices = np.random.permutation(len(X))\n",
    "    \n",
    "    #change 7/12\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    \n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_logit = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "    \n",
    "    preds_voting_weighted = np.zeros(len(y_test))\n",
    "    preds_logit_weighted = np.zeros(len(y_test))\n",
    "    preds_prob_weighted = np.zeros(len(y_test))\n",
    "    \n",
    "    total_cverr = 0\n",
    "    \n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        \n",
    "        # Create a logistic regression model\n",
    "        model = LogisticRegression(max_iter=500)\n",
    "        \n",
    "        # Select the current batch for training\n",
    "        #X_batch = X_train[start_index:end_index]\n",
    "        #y_batch = y_train[start_index:end_index]\n",
    "        \n",
    "        #change 7/12\n",
    "        X_batch = X_train.iloc[indices[start_index:end_index]]\n",
    "        y_batch = y_train.iloc[indices[start_index:end_index]]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model on the current batch\n",
    "        model.fit(X_batch_scaled, y_batch)\n",
    "        current_cverr = cross_val_score(model, X_batch_scaled, y_batch, cv = 5, scoring = 'accuracy').mean()\n",
    "        total_cverr += current_cverr\n",
    "               \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Accumulate the predictions using majority voting\n",
    "        preds_voting += (y_pred == 1)\n",
    "        preds_voting_weighted += (y_pred == 1) * current_cverr\n",
    "    \n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = model.decision_function(X_test_scaled)\n",
    "        preds_logit += y_pred\n",
    "        preds_logit_weighted += y_pred * current_cverr\n",
    "        \n",
    "        #Accumulate the probs\n",
    "        y_pred = model.predict_proba(X_test_scaled)\n",
    "        preds_prob += y_pred[:,1]\n",
    "        preds_prob_weighted += y_pred[:,1] * current_cverr\n",
    "    \n",
    "    accuracy = np.zeros(7)\n",
    "    auc_accuracy = np.zeros(7)\n",
    "    \n",
    "    preds_voting_weighted = preds_voting_weighted / total_cverr * num_batches\n",
    "    preds_logit_weighted = preds_logit_weighted / total_cverr * num_batches\n",
    "    preds_prob_weighted = preds_prob_weighted / total_cverr * num_batches\n",
    "    \n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 1, 0)\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[0] = roc_auc_score(y_test, preds_voting)\n",
    "    \n",
    "    final_predictions = np.where(preds_voting_weighted > num_batches / 2, 1, 0)\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[1] = roc_auc_score(y_test, preds_voting_weighted)\n",
    "    \n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_logit > 0, 1, 0)\n",
    "    accuracy[2] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[2] = roc_auc_score(y_test, preds_logit)\n",
    "    \n",
    "    final_predictions = np.where(preds_logit_weighted > 0, 1, 0)\n",
    "    accuracy[3] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[3] = roc_auc_score(y_test, preds_logit_weighted)\n",
    "    \n",
    "    #Average of probs\n",
    "    final_predictions = np.where(preds_prob / num_batches > 0.5, 1, 0)\n",
    "    accuracy[4] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[4] = roc_auc_score(y_test, preds_prob)\n",
    "    \n",
    "    final_predictions = np.where(preds_prob_weighted / num_batches > 0.5, 1, 0)\n",
    "    accuracy[5] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[5] = roc_auc_score(y_test, preds_prob_weighted)\n",
    "    \n",
    "    # Train a model on all 11 batches of training data\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy[6] = accuracy_score(y_test, y_pred)\n",
    "    y_pred = model.decision_function(X_test_scaled)\n",
    "    auc_accuracy[6] = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, auc_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273e621",
   "metadata": {},
   "source": [
    "Try the divide and conquer approaches 10 times, reporting the following error matrix. \n",
    "- 10-by-4\n",
    "- col_1: majority voting\n",
    "- col_2: average the logit\n",
    "- col_3: average probabilities\n",
    "- col_4: using the model trained on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "67dade4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.79022082 0.79022082 0.78890641 0.78890641 0.78890641 0.78903785\n",
      "  0.78890641]\n",
      " [0.78509464 0.78509464 0.78548896 0.78548896 0.78548896 0.78548896\n",
      "  0.78588328]\n",
      " [0.7898265  0.7898265  0.78956362 0.78943218 0.78956362 0.78943218\n",
      "  0.78930074]\n",
      " [0.79100946 0.79100946 0.79035226 0.79035226 0.79035226 0.7904837\n",
      "  0.79035226]\n",
      " [0.79915878 0.79915878 0.79994742 0.79994742 0.79994742 0.79994742\n",
      "  0.80007886]\n",
      " [0.78128286 0.78128286 0.78325447 0.78325447 0.78325447 0.78325447\n",
      "  0.78299159]\n",
      " [0.79100946 0.79100946 0.79100946 0.79087802 0.79087802 0.79087802\n",
      "  0.79166667]\n",
      " [0.78680336 0.78680336 0.78732913 0.78732913 0.78719769 0.78719769\n",
      "  0.78732913]\n",
      " [0.79258675 0.79258675 0.79035226 0.79061514 0.7904837  0.7904837\n",
      "  0.79061514]\n",
      " [0.79311251 0.79311251 0.79324395 0.79324395 0.79324395 0.79324395\n",
      "  0.79271819]\n",
      " [0.78995794 0.78995794 0.78969506 0.78969506 0.78969506 0.78969506\n",
      "  0.78969506]\n",
      " [0.79390116 0.79390116 0.79376972 0.79376972 0.79363828 0.79376972\n",
      "  0.79337539]\n",
      " [0.79337539 0.79337539 0.79416404 0.7940326  0.79416404 0.7940326\n",
      "  0.79390116]\n",
      " [0.78575184 0.78575184 0.78588328 0.78588328 0.78588328 0.78588328\n",
      "  0.78548896]\n",
      " [0.78798633 0.78798633 0.78759201 0.78772345 0.78759201 0.78772345\n",
      "  0.78759201]\n",
      " [0.79140379 0.79140379 0.79232387 0.79245531 0.79232387 0.79232387\n",
      "  0.79206099]\n",
      " [0.79547844 0.79547844 0.79652997 0.79666141 0.79626709 0.79652997\n",
      "  0.79600421]\n",
      " [0.7982387  0.7982387  0.79731861 0.79731861 0.79731861 0.79731861\n",
      "  0.79784437]\n",
      " [0.78877497 0.78877497 0.78969506 0.78969506 0.78969506 0.78969506\n",
      "  0.78930074]\n",
      " [0.78299159 0.78299159 0.78286015 0.78286015 0.78286015 0.78286015\n",
      "  0.78312303]\n",
      " [0.78995794 0.78995794 0.79232387 0.79192955 0.79232387 0.79206099\n",
      "  0.79140379]\n",
      " [0.78706625 0.78706625 0.7862776  0.78614616 0.78640904 0.7862776\n",
      "  0.78614616]\n",
      " [0.79166667 0.79166667 0.79127234 0.79127234 0.79127234 0.79127234\n",
      "  0.79179811]\n",
      " [0.79271819 0.79271819 0.79245531 0.79219243 0.79219243 0.79206099\n",
      "  0.79311251]\n",
      " [0.79363828 0.79363828 0.79153523 0.79153523 0.79140379 0.79153523\n",
      "  0.79166667]\n",
      " [0.7891693  0.7891693  0.79035226 0.79022082 0.79035226 0.79022082\n",
      "  0.79022082]\n",
      " [0.7904837  0.7904837  0.79087802 0.79061514 0.79087802 0.79061514\n",
      "  0.79140379]\n",
      " [0.79455836 0.79455836 0.79232387 0.79219243 0.79245531 0.79219243\n",
      "  0.79311251]\n",
      " [0.79416404 0.79416404 0.79442692 0.79455836 0.79442692 0.79442692\n",
      "  0.79482124]\n",
      " [0.79442692 0.79442692 0.795347   0.79521556 0.795347   0.79521556\n",
      "  0.79521556]\n",
      " [0.79416404 0.79416404 0.79482124 0.79455836 0.79482124 0.79455836\n",
      "  0.79482124]\n",
      " [0.78614616 0.78614616 0.78522608 0.78483176 0.78509464 0.78509464\n",
      "  0.78509464]\n",
      " [0.79666141 0.79666141 0.79574132 0.79600421 0.79587277 0.79574132\n",
      "  0.79639853]\n",
      " [0.78930074 0.78930074 0.78903785 0.7891693  0.78890641 0.78903785\n",
      "  0.78969506]\n",
      " [0.79876446 0.79876446 0.79942166 0.7995531  0.79929022 0.7995531\n",
      "  0.80047319]\n",
      " [0.78417455 0.78417455 0.78456887 0.78443743 0.78456887 0.78443743\n",
      "  0.78456887]\n",
      " [0.7904837  0.7904837  0.79008938 0.78995794 0.78995794 0.78995794\n",
      "  0.79035226]\n",
      " [0.7946898  0.7946898  0.79245531 0.79258675 0.79245531 0.79245531\n",
      "  0.79245531]\n",
      " [0.7849632  0.7849632  0.78535752 0.78548896 0.78522608 0.78535752\n",
      "  0.78509464]\n",
      " [0.79166667 0.79166667 0.79061514 0.79061514 0.79061514 0.79074658\n",
      "  0.79100946]\n",
      " [0.78930074 0.78930074 0.78864353 0.78851209 0.78890641 0.78864353\n",
      "  0.7904837 ]\n",
      " [0.78864353 0.78864353 0.78930074 0.78943218 0.78930074 0.78930074\n",
      "  0.78930074]\n",
      " [0.79061514 0.79061514 0.79074658 0.79100946 0.79061514 0.79074658\n",
      "  0.79035226]\n",
      " [0.79087802 0.79087802 0.79179811 0.79166667 0.79166667 0.79166667\n",
      "  0.79271819]\n",
      " [0.79206099 0.79206099 0.79153523 0.79153523 0.79153523 0.79166667\n",
      "  0.79206099]\n",
      " [0.78824921 0.78824921 0.78864353 0.78851209 0.78864353 0.78864353\n",
      "  0.78864353]\n",
      " [0.79140379 0.79140379 0.79100946 0.7911409  0.7911409  0.79100946\n",
      "  0.7904837 ]\n",
      " [0.79600421 0.79600421 0.79442692 0.79416404 0.79455836 0.79442692\n",
      "  0.79455836]\n",
      " [0.7911409  0.7911409  0.79127234 0.79127234 0.79140379 0.79140379\n",
      "  0.79179811]\n",
      " [0.79206099 0.79206099 0.79219243 0.79219243 0.79219243 0.79206099\n",
      "  0.79140379]]\n",
      "AUC: [[0.76979465 0.76973873 0.83747954 0.83746256 0.83744868 0.83743716\n",
      "  0.83746931]\n",
      " [0.76857458 0.76859037 0.83519018 0.83519572 0.83511557 0.8351229\n",
      "  0.83498564]\n",
      " [0.77488535 0.77488952 0.84169796 0.84169789 0.84173917 0.84173802\n",
      "  0.84195017]\n",
      " [0.77351864 0.77357363 0.84000626 0.8399903  0.84000482 0.83999567\n",
      "  0.83976867]\n",
      " [0.7803712  0.78046507 0.83866912 0.83864741 0.83899676 0.83898613\n",
      "  0.83870791]\n",
      " [0.77072887 0.77081053 0.83997803 0.83996636 0.84020009 0.84018909\n",
      "  0.83985563]\n",
      " [0.77115333 0.7711668  0.83734832 0.83732168 0.83759659 0.83757999\n",
      "  0.83731527]\n",
      " [0.77646128 0.77659401 0.83907072 0.83904422 0.83947768 0.83945339\n",
      "  0.83912469]\n",
      " [0.78097751 0.78106228 0.83832614 0.8383184  0.83853225 0.83852648\n",
      "  0.83837752]\n",
      " [0.77712826 0.7771539  0.84015452 0.84015841 0.84012956 0.84013246\n",
      "  0.84012842]\n",
      " [0.77404135 0.77405832 0.83785287 0.83784916 0.8380945  0.83809245\n",
      "  0.83801282]\n",
      " [0.78420762 0.78434189 0.8425888  0.84257406 0.84280442 0.84279655\n",
      "  0.84231028]\n",
      " [0.78087683 0.78087232 0.84002164 0.84002111 0.84009676 0.84009054\n",
      "  0.84027707]\n",
      " [0.77563119 0.77560091 0.83986358 0.83986742 0.83982281 0.83983394\n",
      "  0.83976842]\n",
      " [0.76986945 0.76988574 0.83582288 0.83582127 0.83568257 0.83568356\n",
      "  0.83581386]\n",
      " [0.78063376 0.78065518 0.83907427 0.83907526 0.83943419 0.83942925\n",
      "  0.83895554]\n",
      " [0.77987811 0.77985161 0.84455384 0.84456157 0.84473219 0.84474271\n",
      "  0.84437868]\n",
      " [0.78702309 0.78697554 0.84244035 0.84243397 0.84253265 0.84252969\n",
      "  0.84237031]\n",
      " [0.77133396 0.77136758 0.83023753 0.8302229  0.83053712 0.83052932\n",
      "  0.82986744]\n",
      " [0.77695576 0.77698424 0.8328511  0.83282927 0.83310483 0.83308757\n",
      "  0.83288592]\n",
      " [0.77393219 0.77399906 0.83958485 0.83955667 0.8396748  0.83964693\n",
      "  0.83955042]\n",
      " [0.77139458 0.77132471 0.82655769 0.82655655 0.82659343 0.82659191\n",
      "  0.82656507]\n",
      " [0.77304741 0.77313152 0.83457917 0.83456185 0.83463579 0.83461795\n",
      "  0.83473654]\n",
      " [0.77325226 0.77329645 0.83688698 0.83689555 0.83696694 0.83697672\n",
      "  0.83695245]\n",
      " [0.77512279 0.77533499 0.83123621 0.83122546 0.83153935 0.8315315\n",
      "  0.83124109]\n",
      " [0.77393839 0.77394528 0.83899819 0.83900652 0.83900129 0.83900501\n",
      "  0.83895665]\n",
      " [0.77984655 0.77981089 0.84462608 0.84462222 0.84479108 0.8447907\n",
      "  0.84458649]\n",
      " [0.77677228 0.77676197 0.83990564 0.83989747 0.83994732 0.8399432\n",
      "  0.83961349]\n",
      " [0.77845306 0.77852065 0.84068956 0.84068381 0.84104642 0.84102849\n",
      "  0.84055006]\n",
      " [0.77833624 0.77843734 0.84281214 0.84281252 0.84296113 0.84296463\n",
      "  0.84256949]\n",
      " [0.78283293 0.78289939 0.83877517 0.83878329 0.83915701 0.83916058\n",
      "  0.8387398 ]\n",
      " [0.77946868 0.77971492 0.83537806 0.8353534  0.83566665 0.8356541\n",
      "  0.83561394]\n",
      " [0.78658986 0.78661344 0.84340999 0.84340147 0.84363288 0.84362801\n",
      "  0.8434179 ]\n",
      " [0.7757735  0.77573969 0.8411517  0.84115852 0.8413386  0.84134004\n",
      "  0.84113236]\n",
      " [0.7778891  0.77780465 0.84641579 0.84638632 0.84653581 0.84650875\n",
      "  0.84641542]\n",
      " [0.7670704  0.767091   0.83710655 0.83711867 0.83708652 0.83709902\n",
      "  0.8370241 ]\n",
      " [0.77425535 0.77432393 0.83924529 0.83923519 0.83920352 0.83920101\n",
      "  0.83934524]\n",
      " [0.77929101 0.77934542 0.84402633 0.84403079 0.84401134 0.84402451\n",
      "  0.84403246]\n",
      " [0.77129281 0.77121198 0.83719788 0.8372102  0.83706628 0.837078\n",
      "  0.83700693]\n",
      " [0.76956513 0.76963828 0.83614312 0.83614312 0.83625285 0.83625308\n",
      "  0.83626011]\n",
      " [0.77325595 0.77328937 0.84154387 0.84150459 0.84163925 0.84159991\n",
      "  0.84167687]\n",
      " [0.76975559 0.76979229 0.83808614 0.83808817 0.83802672 0.83803002\n",
      "  0.83841186]\n",
      " [0.78081984 0.78091914 0.84191968 0.84189335 0.84220179 0.84217765\n",
      "  0.84187079]\n",
      " [0.77860627 0.77866981 0.83897218 0.83895176 0.83904797 0.83902399\n",
      "  0.83908231]\n",
      " [0.77590568 0.77590908 0.83936964 0.83936851 0.83942786 0.83943058\n",
      "  0.839309  ]\n",
      " [0.77487871 0.77488734 0.83550026 0.83551112 0.83552522 0.83554219\n",
      "  0.83533714]\n",
      " [0.7704283  0.77044721 0.83730364 0.83728789 0.83737197 0.83735895\n",
      "  0.83706603]\n",
      " [0.77574913 0.77579799 0.8391397  0.83912335 0.83922697 0.83920222\n",
      "  0.83945026]\n",
      " [0.77467575 0.77469324 0.83575424 0.83575615 0.83592469 0.83592713\n",
      "  0.83574591]\n",
      " [0.77550544 0.77547323 0.84008571 0.84008055 0.84041825 0.84041195\n",
      "  0.83983097]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = iterate_process(X, y)\n",
    "    seed += 2\n",
    "    \n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "df9593cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79094374, 0.79094374, 0.79086751, 0.79084122, 0.79085174,\n",
       "       0.79083333, 0.79097792])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0b76f33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00387429, 0.00387429, 0.00374648, 0.00376297, 0.00374123,\n",
       "       0.00374397, 0.00383604])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eb08c798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.775835  , 0.77586925, 0.83871258, 0.83870528, 0.83884006,\n",
       "       0.83883451, 0.83868829])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dd556ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00452981, 0.00454062, 0.00367318, 0.00367262, 0.00367974,\n",
       "       0.0036787 , 0.00367083])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf549c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
