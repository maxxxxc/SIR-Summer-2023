{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0ddd4b",
   "metadata": {},
   "source": [
    "# Magic Gamma Telescope\n",
    "\n",
    "Dataset is from https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\n",
    "\n",
    "n = 19020\n",
    "\n",
    "10 features\n",
    "\n",
    "- X1.  fLength:  continuous  # major axis of ellipse [mm]\n",
    "- X2.  fWidth:   continuous  # minor axis of ellipse [mm] \n",
    "- X3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\n",
    "- X4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\n",
    "- X5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\n",
    "- X6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\n",
    "- X7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \n",
    "- X8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\n",
    "- X9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\n",
    "- X10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\n",
    "- Y.  class:    g,h         # gamma (signal), hadron (background)\n",
    "  - g = gamma (signal):     12332\n",
    "  - h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "961a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b861a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/magic04.data\"\n",
    "column_names = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \"Y\"]\n",
    "df = pd.read_csv(url, header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9658e176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19020, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c99a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2      X3      X4      X5        X6       X7       X8  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
      "\n",
      "        X9       X10  Y  \n",
      "0  40.0920   81.8828  g  \n",
      "1   6.3609  205.2610  g  \n",
      "2  76.9600  256.7880  g  \n",
      "3  10.4490  116.7370  g  \n",
      "4   4.6480  356.4620  g  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4330eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff409132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Y\", axis=1)\n",
    "y = df[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c6d4ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    12332\n",
       "h     6688\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f77bf697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12332\n",
       "0     6688\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.replace({'g' : 1, 'h' : 0})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d8a20",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b2ba396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.790571328426218\n",
      "Test Accuracy: 0.7879863301787592\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "#model = LogisticRegression()\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a20454",
   "metadata": {},
   "source": [
    "# Divide and Conquer\n",
    "\n",
    "Divide the training data into 11 batches, train a logistic model on each of the batch, and then combine the 11 prediction results. Consider the following two ensemble methods:\n",
    "- majority voting\n",
    "- average (or sum) of the logit output and then make decision based on its sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "806458ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "   \n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    #indices = np.random.permutation(len(X))\n",
    "    \n",
    "    #change 7/12\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "\n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    \n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_logit = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        \n",
    "        # Create a logistic regression model\n",
    "        model = LogisticRegression(max_iter=500)\n",
    "        \n",
    "        # Select the current batch for training\n",
    "        #X_batch = X_train[start_index:end_index]\n",
    "        #y_batch = y_train[start_index:end_index]\n",
    "        \n",
    "        #change 7/12\n",
    "        X_batch = X_train.iloc[indices[start_index:end_index]]\n",
    "        y_batch = y_train.iloc[indices[start_index:end_index]]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model on the current batch\n",
    "        model.fit(X_batch_scaled, y_batch)\n",
    "               \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Accumulate the predictions using majority voting\n",
    "        preds_voting += (y_pred == 1)\n",
    "    \n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = model.decision_function(X_test_scaled)\n",
    "        preds_logit += y_pred\n",
    "        \n",
    "        #Accumulate the probs\n",
    "        y_pred = model.predict_proba(X_test_scaled)\n",
    "        preds_prob += y_pred[:,1]\n",
    "   \n",
    "    \n",
    "    accuracy = np.zeros(4)\n",
    "    \n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 1, 0)\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_logit > 0, 1, 0)\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    #Average of probs\n",
    "    final_predictions = np.where(preds_prob / num_batches > 0.5, 1, 0)\n",
    "    accuracy[2] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    # Train a model on all 11 batches of training data\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy[3] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273e621",
   "metadata": {},
   "source": [
    "Try the divide and conquer approaches 10 times, reporting the following error matrix. \n",
    "- 10-by-4\n",
    "- col_1: majority voting\n",
    "- col_2: average the logit\n",
    "- col_3: average probabilities\n",
    "- col_4: using the model trained on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67dade4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.79022082 0.78890641 0.78890641 0.78890641]\n",
      " [0.78509464 0.78548896 0.78548896 0.78588328]\n",
      " [0.7898265  0.78956362 0.78956362 0.78930074]\n",
      " [0.79100946 0.79035226 0.79035226 0.79035226]\n",
      " [0.79915878 0.79994742 0.79994742 0.80007886]\n",
      " [0.78128286 0.78325447 0.78325447 0.78299159]\n",
      " [0.79100946 0.79100946 0.79087802 0.79166667]\n",
      " [0.78680336 0.78732913 0.78719769 0.78732913]\n",
      " [0.79258675 0.79035226 0.7904837  0.79061514]\n",
      " [0.79311251 0.79324395 0.79324395 0.79271819]\n",
      " [0.78995794 0.78969506 0.78969506 0.78969506]\n",
      " [0.79390116 0.79376972 0.79363828 0.79337539]\n",
      " [0.79337539 0.79416404 0.79416404 0.79390116]\n",
      " [0.78575184 0.78588328 0.78588328 0.78548896]\n",
      " [0.78798633 0.78759201 0.78759201 0.78759201]\n",
      " [0.79140379 0.79232387 0.79232387 0.79206099]\n",
      " [0.79547844 0.79652997 0.79626709 0.79600421]\n",
      " [0.7982387  0.79731861 0.79731861 0.79784437]\n",
      " [0.78877497 0.78969506 0.78969506 0.78930074]\n",
      " [0.78299159 0.78286015 0.78286015 0.78312303]\n",
      " [0.78995794 0.79232387 0.79232387 0.79140379]\n",
      " [0.78706625 0.7862776  0.78640904 0.78614616]\n",
      " [0.79166667 0.79127234 0.79127234 0.79179811]\n",
      " [0.79271819 0.79245531 0.79219243 0.79311251]\n",
      " [0.79363828 0.79153523 0.79140379 0.79166667]\n",
      " [0.7891693  0.79035226 0.79035226 0.79022082]\n",
      " [0.7904837  0.79087802 0.79087802 0.79140379]\n",
      " [0.79455836 0.79232387 0.79245531 0.79311251]\n",
      " [0.79416404 0.79442692 0.79442692 0.79482124]\n",
      " [0.79442692 0.795347   0.795347   0.79521556]\n",
      " [0.79416404 0.79482124 0.79482124 0.79482124]\n",
      " [0.78614616 0.78522608 0.78509464 0.78509464]\n",
      " [0.79666141 0.79574132 0.79587277 0.79639853]\n",
      " [0.78930074 0.78903785 0.78890641 0.78969506]\n",
      " [0.79876446 0.79942166 0.79929022 0.80047319]\n",
      " [0.78417455 0.78456887 0.78456887 0.78456887]\n",
      " [0.7904837  0.79008938 0.78995794 0.79035226]\n",
      " [0.7946898  0.79245531 0.79245531 0.79245531]\n",
      " [0.7849632  0.78535752 0.78522608 0.78509464]\n",
      " [0.79166667 0.79061514 0.79061514 0.79100946]\n",
      " [0.78930074 0.78864353 0.78890641 0.7904837 ]\n",
      " [0.78864353 0.78930074 0.78930074 0.78930074]\n",
      " [0.79061514 0.79074658 0.79061514 0.79035226]\n",
      " [0.79087802 0.79179811 0.79166667 0.79271819]\n",
      " [0.79206099 0.79153523 0.79153523 0.79206099]\n",
      " [0.78824921 0.78864353 0.78864353 0.78864353]\n",
      " [0.79140379 0.79100946 0.7911409  0.7904837 ]\n",
      " [0.79600421 0.79442692 0.79455836 0.79455836]\n",
      " [0.7911409  0.79127234 0.79140379 0.79179811]\n",
      " [0.79206099 0.79219243 0.79219243 0.79140379]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 4))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i] = iterate_process(X, y)\n",
    "    seed += 2\n",
    "    \n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2065cb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79094374, 0.79086751, 0.79085174, 0.79097792])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe1ba58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00387429, 0.00374648, 0.00374123, 0.00383604])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "593a0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    indices = np.random.permutation(len(X))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f532a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37f49c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78430599, 0.78548896, 0.78548896, 0.78575184])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_process(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6856d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
