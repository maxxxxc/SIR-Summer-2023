{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9421c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b382675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panda\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Extract features (pixel values) and target labels\n",
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2b39fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6825\n",
       "1    6313\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = np.bincount(y)\n",
    "\n",
    "\n",
    "digit_filter = (y == 5) | (y == 8)\n",
    "X = X[digit_filter]\n",
    "y = y[digit_filter]\n",
    "\n",
    "np.unique(y)\n",
    "\n",
    "n5 = np.count_nonzero(y == 5)\n",
    "n8 = np.count_nonzero(y == 8)\n",
    "\n",
    "y = y.replace({5 : 1, 8 : 0})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ad36cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b00dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76e9aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b2271e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
    "#svm = SVC(kernel='rbf')\n",
    "\n",
    "#grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "#grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "#best_params = grid_search.best_params_\n",
    "#best_C = best_params['C']\n",
    "#best_gamma = best_params['gamma']\n",
    "\n",
    "best_C = 1\n",
    "best_gamma = 1\n",
    "\n",
    "#Fit the SVM with the best parameters:\n",
    "svm = SVC(kernel='rbf', C=best_C, gamma=best_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56e67f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd42742e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5154109589041096\n",
      "Match between Prediction and Rule based on Distance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Prediction rule is essentially: 1 if distance > 0\n",
    "distances = svm.decision_function(X_test_scaled)\n",
    "tmp = np.where(distances > 0, 1, 0)\n",
    "print(\"Match between Prediction and Rule based on Distance\")\n",
    "accuracy_score(tmp, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbe4ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68347644",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_platt = CalibratedClassifierCV(svm)\n",
    "svm_platt.fit(X_train_scaled, y_train)\n",
    "y_test_prob = svm_platt.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f7ab1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5154109589041096"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = np.where(y_test_prob[:,1] > 0.5, 1, 0)\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ee03d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    \n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    \n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_distance = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        \n",
    "        # Select the current batch for training\n",
    "        X_batch = X_train.iloc[indices[start_index:end_index]]\n",
    "        y_batch = y_train.iloc[indices[start_index:end_index]]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        # Create a support vector machine model\n",
    "        param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
    "        svm = SVC(kernel='rbf')\n",
    "\n",
    "        grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "        grid_search.fit(X_batch_scaled, y_batch)\n",
    "\n",
    "        best_params = grid_search.best_params_\n",
    "        best_C = best_params['C']\n",
    "        best_gamma = best_params['gamma']\n",
    "        svm = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "        \n",
    "        # Fit the model on the current batch\n",
    "        svm.fit(X_batch_scaled, y_batch)\n",
    "        \n",
    "               \n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = svm.predict(X_test_scaled)\n",
    "        preds_voting += (y_pred == 1)\n",
    "\n",
    "    \n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = svm.decision_function(X_test_scaled)\n",
    "        preds_distance += y_pred\n",
    "        \n",
    "        \n",
    "        #Accumulate the probs\n",
    "        svm_platt = CalibratedClassifierCV(svm)\n",
    "        svm_platt.fit(X_batch_scaled, y_batch)\n",
    "        y_pred = svm_platt.predict_proba(X_test_scaled)\n",
    "        preds_prob += y_pred[:,1]\n",
    "   \n",
    "    \n",
    "    accuracy = np.zeros(4)\n",
    "    \n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 1, 0)\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_distance > 0, 1, 0)\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    #Average of probs\n",
    "    final_predictions = np.where(preds_prob / num_batches > 0.5, 1, 0)\n",
    "    accuracy[2] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    # Train a model on all 11 batches of training data\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
    "    svm = SVC(kernel='rbf')\n",
    "\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_C = best_params['C']\n",
    "    best_gamma = best_params['gamma']\n",
    "    svm = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "    \n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "    accuracy[3] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9674cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.51541096 0.51541096 0.52111872 0.51541096]\n",
      " [0.52187976 0.52187976 0.52739726 0.52187976]\n",
      " [0.53120244 0.53120244 0.54642314 0.53120244]\n",
      " [0.51217656 0.51217656 0.51369863 0.51217656]\n",
      " [0.52283105 0.52283105 0.52644597 0.52283105]\n",
      " [0.52454338 0.52454338 0.52949011 0.52454338]\n",
      " [0.52016743 0.52016743 0.52454338 0.52016743]\n",
      " [0.52910959 0.52910959 0.53710046 0.52910959]\n",
      " [0.52454338 0.52454338 0.52739726 0.52454338]\n",
      " [0.52207002 0.52207002 0.52340183 0.52207002]\n",
      " [0.52758752 0.52758752 0.53082192 0.52758752]\n",
      " [0.51959665 0.51959665 0.52207002 0.51959665]\n",
      " [0.50589802 0.50589802 0.50703957 0.50589802]\n",
      " [0.5207382  0.5207382  0.52321157 0.5207382 ]\n",
      " [0.52245053 0.52245053 0.53310502 0.52245053]\n",
      " [0.52872907 0.52872907 0.53272451 0.52872907]\n",
      " [0.52606545 0.52606545 0.5304414  0.52606545]\n",
      " [0.51921613 0.51921613 0.52606545 0.51921613]\n",
      " [0.51179604 0.51179604 0.51598174 0.51179604]\n",
      " [0.52644597 0.52644597 0.53633942 0.52644597]\n",
      " [0.51883562 0.51883562 0.51940639 0.51883562]\n",
      " [0.51997717 0.51997717 0.52111872 0.51997717]\n",
      " [0.51160578 0.51160578 0.51331811 0.51160578]\n",
      " [0.51617199 0.51617199 0.5184551  0.51617199]\n",
      " [0.52207002 0.52207002 0.52606545 0.52207002]\n",
      " [0.52111872 0.52111872 0.5249239  0.52111872]\n",
      " [0.52758752 0.52758752 0.53253425 0.52758752]\n",
      " [0.52245053 0.52245053 0.52454338 0.52245053]\n",
      " [0.51864536 0.51864536 0.52187976 0.51864536]\n",
      " [0.51750381 0.51750381 0.51883562 0.51750381]\n",
      " [0.51503044 0.51503044 0.51750381 0.51503044]\n",
      " [0.5207382  0.5207382  0.52568493 0.5207382 ]\n",
      " [0.51426941 0.51426941 0.51978691 0.51426941]\n",
      " [0.51103501 0.51103501 0.51902588 0.51103501]\n",
      " [0.52283105 0.52283105 0.52834855 0.52283105]\n",
      " [0.52435312 0.52435312 0.52910959 0.52435312]\n",
      " [0.51826484 0.51826484 0.5216895  0.51826484]\n",
      " [0.52016743 0.52016743 0.52130898 0.52016743]\n",
      " [0.52416286 0.52416286 0.52625571 0.52416286]\n",
      " [0.51065449 0.51065449 0.51217656 0.51065449]\n",
      " [0.5207382  0.5207382  0.52587519 0.5207382 ]\n",
      " [0.51921613 0.51921613 0.52530441 0.51921613]\n",
      " [0.52435312 0.52435312 0.52872907 0.52435312]\n",
      " [0.51598174 0.51598174 0.51712329 0.51598174]\n",
      " [0.51731355 0.51731355 0.51959665 0.51731355]\n",
      " [0.5216895  0.5216895  0.52283105 0.5216895 ]\n",
      " [0.50761035 0.50761035 0.50856164 0.50761035]\n",
      " [0.52321157 0.52321157 0.52625571 0.52321157]\n",
      " [0.527207   0.527207   0.53215373 0.527207  ]\n",
      " [0.50799087 0.50799087 0.50913242 0.50799087]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 4))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "    \n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "083dc8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51990487, 0.51990487, 0.52384703, 0.51990487])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a995cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00578986, 0.00578986, 0.00749355, 0.00578986])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecf81579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52220234, 0.47779766],\n",
       "       [0.52220234, 0.47779766],\n",
       "       [0.52220234, 0.47779766],\n",
       "       [0.52220234, 0.47779766],\n",
       "       [0.52220234, 0.47779766]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prob[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80a3eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "train_distances = svm.decision_function(X_train_scaled)\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(train_distances.reshape(-1, 1), y_train)\n",
    "tmp = model.predict_proba(distances.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d838f253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58731648, 0.41268352],\n",
       "       [0.58731648, 0.41268352],\n",
       "       [0.58731648, 0.41268352],\n",
       "       [0.58731648, 0.41268352],\n",
       "       [0.58731648, 0.41268352]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f927858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5154109589041096"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = np.where(tmp[:,1] > 0.5, 1, 0)\n",
    "accuracy_score(y_test, tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f19e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
