{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0ddd4b",
   "metadata": {},
   "source": [
    "# APS Failure at Scania Trucks\n",
    "\n",
    "Dataset is from https://archive.ics.uci.edu/dataset/421/aps+failure+at+scania+trucks\n",
    "\n",
    "n = 60000\n",
    "\n",
    "171 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b861a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/aps_failure_test_set.csv\"\n",
    "#df = pd.read_csv(url, na_values = 'na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6462e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training dataset from CSV\n",
    "train_df = pd.read_csv(url, na_values = 'na')\n",
    "\n",
    "# Read the test dataset from CSV\n",
    "test_df = pd.read_csv(url, na_values = 'na')\n",
    "\n",
    "# Add a 'Label' column to the test dataset and fill it with NaN values\n",
    "#test_df['Label'] = float('nan')\n",
    "\n",
    "# Concatenate the training and test datasets\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset to a new CSV file\n",
    "df.to_csv('combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9658e176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 171)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c99a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class  aa_000  ab_000  ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
      "0   neg      60     0.0    20.0    12.0     0.0     0.0     0.0     0.0   \n",
      "1   neg      82     0.0    68.0    40.0     0.0     0.0     0.0     0.0   \n",
      "2   neg   66002     2.0   212.0   112.0     0.0     0.0     0.0     0.0   \n",
      "3   neg   59816     NaN  1010.0   936.0     0.0     0.0     0.0     0.0   \n",
      "4   neg    1814     NaN   156.0   140.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   ag_002  ...    ee_002    ee_003    ee_004    ee_005     ee_006    ee_007  \\\n",
      "0     0.0  ...    1098.0     138.0     412.0     654.0       78.0      88.0   \n",
      "1     0.0  ...    1068.0     276.0    1620.0     116.0       86.0     462.0   \n",
      "2     0.0  ...  495076.0  380368.0  440134.0  269556.0  1315022.0  153680.0   \n",
      "3     0.0  ...  540820.0  243270.0  483302.0  485332.0   431376.0  210074.0   \n",
      "4     0.0  ...    7646.0    4144.0   18466.0   49782.0     3176.0     482.0   \n",
      "\n",
      "     ee_008  ee_009  ef_000  eg_000  \n",
      "0       0.0     0.0     0.0     0.0  \n",
      "1       0.0     0.0     0.0     0.0  \n",
      "2     516.0     0.0     0.0     0.0  \n",
      "3  281662.0  3232.0     0.0     0.0  \n",
      "4      76.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55d1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br_000    26258\n",
      "bq_000    25962\n",
      "bp_000    25442\n",
      "bo_000    24752\n",
      "ab_000    24726\n",
      "          ...  \n",
      "cj_000      172\n",
      "ci_000      172\n",
      "bt_000       56\n",
      "aa_000        0\n",
      "class         0\n",
      "Length: 171, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = df.isna().sum()\n",
    "\n",
    "print(missing_values_count.sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4330eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff409132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f98305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for na values\n",
    "threshold = len(X) * 0.5\n",
    "X = X.dropna(thresh = threshold, axis = 1)\n",
    "\n",
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12ec0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>ag_004</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>4736.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>68.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66002</td>\n",
       "      <td>212.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199486.0</td>\n",
       "      <td>1358536.0</td>\n",
       "      <td>...</td>\n",
       "      <td>495076.0</td>\n",
       "      <td>380368.0</td>\n",
       "      <td>440134.0</td>\n",
       "      <td>269556.0</td>\n",
       "      <td>1315022.0</td>\n",
       "      <td>153680.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59816</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>540820.0</td>\n",
       "      <td>243270.0</td>\n",
       "      <td>483302.0</td>\n",
       "      <td>485332.0</td>\n",
       "      <td>431376.0</td>\n",
       "      <td>210074.0</td>\n",
       "      <td>281662.0</td>\n",
       "      <td>3232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1814</td>\n",
       "      <td>156.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7646.0</td>\n",
       "      <td>4144.0</td>\n",
       "      <td>18466.0</td>\n",
       "      <td>49782.0</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa_000  ac_000  ad_000  ae_000  af_000  ag_000  ag_001  ag_002    ag_003  \\\n",
       "0      60    20.0    12.0     0.0     0.0     0.0     0.0     0.0    2682.0   \n",
       "1      82    68.0    40.0     0.0     0.0     0.0     0.0     0.0       0.0   \n",
       "2   66002   212.0   112.0     0.0     0.0     0.0     0.0     0.0  199486.0   \n",
       "3   59816  1010.0   936.0     0.0     0.0     0.0     0.0     0.0       0.0   \n",
       "4    1814   156.0   140.0     0.0     0.0     0.0     0.0     0.0       0.0   \n",
       "\n",
       "      ag_004  ...    ee_002    ee_003    ee_004    ee_005     ee_006  \\\n",
       "0     4736.0  ...    1098.0     138.0     412.0     654.0       78.0   \n",
       "1      748.0  ...    1068.0     276.0    1620.0     116.0       86.0   \n",
       "2  1358536.0  ...  495076.0  380368.0  440134.0  269556.0  1315022.0   \n",
       "3   123922.0  ...  540820.0  243270.0  483302.0  485332.0   431376.0   \n",
       "4       72.0  ...    7646.0    4144.0   18466.0   49782.0     3176.0   \n",
       "\n",
       "     ee_007    ee_008  ee_009  ef_000  eg_000  \n",
       "0      88.0       0.0     0.0     0.0     0.0  \n",
       "1     462.0       0.0     0.0     0.0     0.0  \n",
       "2  153680.0     516.0     0.0     0.0     0.0  \n",
       "3  210074.0  281662.0  3232.0     0.0     0.0  \n",
       "4     482.0      76.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6d4ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    31250\n",
       "pos      750\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c770dce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 162)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "848faca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31250\n",
       "1      750\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.replace({\"neg\" : 0, \"pos\" : 1})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d8a20",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b2ba396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9905729166666667\n",
      "Test Accuracy: 0.987734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "#model = LogisticRegression()\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a20454",
   "metadata": {},
   "source": [
    "# Divide and Conquer\n",
    "\n",
    "Divide the training data into 11 batches, train a logistic model on each of the batch, and then combine the 11 prediction results. Consider the following two ensemble methods:\n",
    "- majority voting\n",
    "- average (or sum) of the logit output and then make decision based on its sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "806458ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    \n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "    \n",
    "    # Randomly shuffle the data indices\n",
    "    #indices = np.random.permutation(len(X))\n",
    "    \n",
    "    #change 7/12\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "    \n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "    \n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_logit = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        \n",
    "        # Create a logistic regression model\n",
    "        model = LogisticRegression(max_iter=500)\n",
    "        \n",
    "        # Select the current batch for training\n",
    "        X_batch = X_train.iloc[indices[start_index:end_index]]\n",
    "        y_batch = y_train.iloc[indices[start_index:end_index]]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model on the current batch\n",
    "        model.fit(X_batch_scaled, y_batch)\n",
    "               \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Accumulate the predictions using majority voting\n",
    "        preds_voting += (y_pred == 1)\n",
    "    \n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = model.decision_function(X_test_scaled)\n",
    "        preds_logit += y_pred\n",
    "        \n",
    "        #Accumulate the probs\n",
    "        y_pred = model.predict_proba(X_test_scaled)\n",
    "        preds_prob += y_pred[:,1]\n",
    "   \n",
    "    \n",
    "    accuracy = np.zeros(4)\n",
    "    \n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 1, 0)\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_logit > 0, 1, 0)\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    #Average of probs\n",
    "    final_predictions = np.where(preds_prob / num_batches > 0.5, 1, 0)\n",
    "    accuracy[2] = accuracy_score(y_test, final_predictions)\n",
    "    \n",
    "    # Train a model on all 11 batches of training data\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy[3] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273e621",
   "metadata": {},
   "source": [
    "Try the divide and conquer approaches 10 times, reporting the following error matrix. \n",
    "- 10-by-4\n",
    "- col_1: majority voting\n",
    "- col_2: average the logit\n",
    "- col_3: average probabilities\n",
    "- col_4: using the model trained on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67dade4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.9884375  0.98554688 0.988125   0.990625  ]\n",
      " [0.98882812 0.98710937 0.98914062 0.99070313]\n",
      " [0.98898438 0.98726563 0.98882812 0.99046875]\n",
      " [0.989375   0.98820312 0.98945313 0.9909375 ]\n",
      " [0.98773438 0.98515625 0.98835938 0.98960938]\n",
      " [0.986875   0.9859375  0.98734375 0.98882812]\n",
      " [0.98929687 0.98664063 0.98914062 0.99195312]\n",
      " [0.98796875 0.98671875 0.98820312 0.99171875]\n",
      " [0.9875     0.98546875 0.98757812 0.99054688]\n",
      " [0.98898438 0.98765625 0.98921875 0.99140625]\n",
      " [0.98929687 0.9865625  0.98859375 0.99007813]\n",
      " [0.98914062 0.98796875 0.98875    0.99179688]\n",
      " [0.98875    0.98890625 0.9890625  0.99078125]\n",
      " [0.989375   0.98734375 0.9896875  0.99070313]\n",
      " [0.9878125  0.98710937 0.9878125  0.98984375]\n",
      " [0.98960938 0.98796875 0.98945313 0.99195312]\n",
      " [0.988125   0.9871875  0.98789063 0.98984375]\n",
      " [0.98890625 0.98859375 0.98851563 0.99140625]\n",
      " [0.98851563 0.98734375 0.98828125 0.98992187]\n",
      " [0.98710937 0.98460938 0.98734375 0.98945313]\n",
      " [0.98828125 0.9846875  0.98820312 0.99101562]\n",
      " [0.98921875 0.9859375  0.98914062 0.9903125 ]\n",
      " [0.98765625 0.9871875  0.98773438 0.98945313]\n",
      " [0.98710937 0.98617188 0.98742188 0.99039062]\n",
      " [0.98921875 0.98875    0.98976562 0.9896875 ]\n",
      " [0.98679688 0.98578125 0.98632812 0.98820312]\n",
      " [0.98890625 0.98640625 0.98851563 0.9903125 ]\n",
      " [0.98828125 0.98734375 0.98828125 0.98984375]\n",
      " [0.9871875  0.98617188 0.98726563 0.99117188]\n",
      " [0.99       0.98695312 0.99039062 0.99054688]\n",
      " [0.98945313 0.9884375  0.98992187 0.99117188]\n",
      " [0.98859375 0.98671875 0.98851563 0.98976562]\n",
      " [0.98890625 0.98804687 0.98921875 0.9896875 ]\n",
      " [0.9884375  0.98554688 0.98820312 0.99015625]\n",
      " [0.98671875 0.98398438 0.98695312 0.99007813]\n",
      " [0.98765625 0.98648437 0.98757812 0.99046875]\n",
      " [0.98789063 0.98632812 0.9878125  0.99015625]\n",
      " [0.98710937 0.98523437 0.98664063 0.988125  ]\n",
      " [0.98882812 0.9878125  0.98898438 0.9903125 ]\n",
      " [0.98914062 0.98828125 0.989375   0.99125   ]\n",
      " [0.98765625 0.986875   0.9878125  0.99039062]\n",
      " [0.98835938 0.98625    0.98835938 0.99148437]\n",
      " [0.98757812 0.986875   0.98828125 0.9903125 ]\n",
      " [0.98992187 0.98734375 0.98976562 0.99085937]\n",
      " [0.9884375  0.98726563 0.98835938 0.99      ]\n",
      " [0.98867187 0.98757812 0.98859375 0.99195312]\n",
      " [0.98835938 0.98734375 0.9890625  0.99085937]\n",
      " [0.98835938 0.98671875 0.988125   0.99023438]\n",
      " [0.9903125  0.98914062 0.99023438 0.9909375 ]\n",
      " [0.98859375 0.98710937 0.98828125 0.990625  ]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 4))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i] = iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7715f708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98844531, 0.98688125, 0.98847812, 0.99044687])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dba311e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00086873, 0.00113212, 0.00089326, 0.00084621])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05480309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
