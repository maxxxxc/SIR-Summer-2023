{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8043685",
   "metadata": {
    "id": "a8043685"
   },
   "source": [
    "# Magic SVM Weighted + Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb3eb82",
   "metadata": {
    "id": "2bb3eb82"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b382675",
   "metadata": {
    "id": "5b382675",
    "outputId": "69f835fb-83c4-47e1-8db8-5c794a4307f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g    12332\n",
      "h     6688\n",
      "Name: Y, dtype: int64\n",
      "1    12332\n",
      "0     6688\n",
      "Name: Y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/magic04.data\"\n",
    "column_names = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \"Y\"]\n",
    "df = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "p = 10\n",
    "\n",
    "X = df.drop(\"Y\", axis=1)\n",
    "y = df[\"Y\"]\n",
    "print(y.value_counts())\n",
    "y = y.replace({'g': 1, 'h': 0})\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e5371c",
   "metadata": {
    "id": "c9e5371c"
   },
   "outputs": [],
   "source": [
    "def svm_iterate_process2(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "\n",
    "    # Randomly shuffle the data indices\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "\n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "\n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_distance = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "\n",
    "    preds_voting_weighted = np.zeros(len(y_test))\n",
    "    preds_distance_weighted = np.zeros(len(y_test))\n",
    "    preds_prob_weighted = np.zeros(len(y_test))\n",
    "\n",
    "    total_cverr = 0\n",
    "\n",
    "    # Split the training data into batches, fit a logistic regression model on each batch\n",
    "    for i in range(num_batches):\n",
    "        # Calculate the starting and ending indices for the current batch\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "\n",
    "        # Select the current batch for training\n",
    "        X_batch = X_train.iloc[indices[start_index:end_index]]\n",
    "        y_batch = y_train.iloc[indices[start_index:end_index]]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Create a support vector machine model\n",
    "        param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1 / p, 1 / p, 10 / p]}\n",
    "        svm = SVC(kernel='rbf')\n",
    "\n",
    "        grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "        grid_search.fit(X_batch_scaled, y_batch)\n",
    "\n",
    "        best_params = grid_search.best_params_\n",
    "        best_C = best_params['C']\n",
    "        best_gamma = best_params['gamma']\n",
    "        svm = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "        # Fit the model on the current batch\n",
    "        svm.fit(X_batch_scaled, y_batch)\n",
    "        current_cverr = cross_val_score(svm, X_batch_scaled, y_batch, cv = 5, scoring = 'accuracy').mean()\n",
    "        total_cverr += current_cverr\n",
    "\n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = svm.predict(X_test_scaled)\n",
    "        preds_voting += (y_pred == 1)\n",
    "        preds_voting_weighted += (y_pred == 1) * current_cverr\n",
    "\n",
    "        # Accumulate the predictions using majority voting\n",
    "        y_pred = svm.decision_function(X_test_scaled)\n",
    "        preds_distance += y_pred\n",
    "        preds_distance_weighted += y_pred * current_cverr\n",
    "\n",
    "        #Accumulate the probs\n",
    "        svm_platt = CalibratedClassifierCV(svm)\n",
    "        svm_platt.fit(X_batch_scaled, y_batch)\n",
    "        y_pred = svm_platt.predict_proba(X_test_scaled)\n",
    "        preds_prob += y_pred[:,1]\n",
    "        preds_prob_weighted += y_pred[:,1] * current_cverr\n",
    "\n",
    "    accuracy = np.zeros(7)\n",
    "    auc_accuracy = np.zeros(7)\n",
    "\n",
    "    preds_voting_weighted = preds_voting_weighted / total_cverr * num_batches\n",
    "    preds_distance_weighted = preds_distance_weighted / total_cverr * num_batches\n",
    "    preds_prob_weighted = preds_prob_weighted / total_cverr * num_batches\n",
    "\n",
    "    # Majority voting (selecting the most frequent prediction for each sample)\n",
    "    final_predictions = np.where(preds_voting > num_batches / 2, 1, 0)\n",
    "    accuracy[0] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[0] = roc_auc_score(y_test, preds_voting)\n",
    "\n",
    "    final_predictions = np.where(preds_voting_weighted > num_batches / 2, 1, 0)\n",
    "    accuracy[1] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[1] = roc_auc_score(y_test, preds_voting_weighted)\n",
    "\n",
    "    # Average of logit\n",
    "    final_predictions = np.where(preds_distance > 0, 1, 0)\n",
    "    accuracy[2] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[2] = roc_auc_score(y_test, preds_distance)\n",
    "\n",
    "    final_predictions = np.where(preds_distance_weighted > 0, 1, 0)\n",
    "    accuracy[3] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[3] = roc_auc_score(y_test, preds_distance_weighted)\n",
    "\n",
    "    #Average of probs\n",
    "    final_predictions = np.where(preds_prob / num_batches > 0.5, 1, 0)\n",
    "    accuracy[4] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[4] = roc_auc_score(y_test, preds_prob)\n",
    "\n",
    "    final_predictions = np.where(preds_prob_weighted / num_batches > 0.5, 1, 0)\n",
    "    accuracy[5] = accuracy_score(y_test, final_predictions)\n",
    "    auc_accuracy[5] = roc_auc_score(y_test, preds_prob_weighted)\n",
    "\n",
    "    # Train a model on all 11 batches of training data\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1 / p, 1 / p, 10 / p]}\n",
    "    svm = SVC(kernel='rbf')\n",
    "\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_C = best_params['C']\n",
    "    best_gamma = best_params['gamma']\n",
    "    svm = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "    accuracy[6] = accuracy_score(y_test, y_pred)\n",
    "    y_pred = svm.decision_function(X_test_scaled)\n",
    "    auc_accuracy[6] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, auc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b599cabd",
   "metadata": {
    "id": "b599cabd"
   },
   "outputs": [],
   "source": [
    "def svm_iterate_process(X, y):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "    # Define the number of batches\n",
    "    num_batches = 11\n",
    "\n",
    "    # Randomly shuffle the data indices\n",
    "    indices = np.random.permutation(len(X_train))\n",
    "\n",
    "    # Calculate the batch size\n",
    "    batch_size = len(X_train) // num_batches\n",
    "\n",
    "    # Make predictions on the test set using majority voting\n",
    "    preds_voting = np.zeros(len(y_test))\n",
    "    # Make predictions on the test set using average of logit\n",
    "    preds_distance = np.zeros(len(y_test))\n",
    "    #Make predictions on the test set using average of probs\n",
    "    preds_prob = np.zeros(len(y_test))\n",
    "\n",
    "    preds_voting_weighted = np.zeros(len(y_test))\n",
    "    preds_distance_weighted = np.zeros(len(y_test))\n",
    "    preds_prob_weighted = np.zeros(len(y_test))\n",
    "\n",
    "    total_cverr = 0\n",
    "\n",
    "    accuracy = np.zeros(7)\n",
    "    auc_accuracy = np.zeros(7)\n",
    "\n",
    "    # Train a model on all 11 batches of training data\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1 / p, 1 / p, 10 / p]}\n",
    "    svm = SVC(kernel='rbf')\n",
    "\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_C = best_params['C']\n",
    "    best_gamma = best_params['gamma']\n",
    "    svm = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "    accuracy[6] = accuracy_score(y_test, y_pred)\n",
    "    y_pred = svm.decision_function(X_test_scaled)\n",
    "    auc_accuracy[6] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, auc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b9760d",
   "metadata": {
    "id": "e3b9760d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_repeats):\n\u001b[0;32m     11\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m---> 12\u001b[0m     accuracies[i], auc_accuracies[i] \u001b[38;5;241m=\u001b[39m svm_iterate_process(X, y)\n\u001b[0;32m     13\u001b[0m     seed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Print the accuracies\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae6fb5",
   "metadata": {
    "id": "7fae6fb5"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a238d89",
   "metadata": {
    "id": "7a238d89"
   },
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374c454",
   "metadata": {
    "id": "8374c454"
   },
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ca7db",
   "metadata": {
    "id": "460ca7db"
   },
   "outputs": [],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45582a17",
   "metadata": {
    "id": "45582a17"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd7f1c03",
   "metadata": {
    "id": "dd7f1c03"
   },
   "source": [
    "# Wireless Indoor Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3c4f4",
   "metadata": {
    "id": "0aa3c4f4"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/wifi_localization.txt\"\n",
    "df = pd.read_csv(url, sep = '\\t', header = None)\n",
    "\n",
    "p = 6\n",
    "\n",
    "X = df.drop(7, axis=1)\n",
    "y = df[7]\n",
    "print(y.value_counts())\n",
    "y = y.replace({2 : 0, 1 : 0, 3: 1, 4 : 1})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fc2b0",
   "metadata": {
    "id": "c73fc2b0"
   },
   "outputs": [],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6931f9fd",
   "metadata": {
    "id": "6931f9fd"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ebf0f",
   "metadata": {
    "id": "100ebf0f"
   },
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc18822",
   "metadata": {
    "id": "0bc18822"
   },
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3dd0e1",
   "metadata": {
    "id": "0e3dd0e1"
   },
   "outputs": [],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463cea2",
   "metadata": {
    "id": "6463cea2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362613c5",
   "metadata": {
    "id": "362613c5"
   },
   "source": [
    "# Turkiye Student Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038906ad",
   "metadata": {
    "id": "038906ad"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/turkiye-student-evaluation_generic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "p = 32\n",
    "\n",
    "X = df.drop(\"difficulty\", axis=1)\n",
    "y = df[\"difficulty\"]\n",
    "\n",
    "X = X.drop(\"instr\", axis=1)\n",
    "X = X.drop(\"class\", axis=1)\n",
    "X = X.drop(\"nb.repeat\", axis=1)\n",
    "X = X.drop(\"attendance\", axis=1)\n",
    "\n",
    "print(y.value_counts())\n",
    "y = y.replace({2 : 0, 1 : 0, 3: 1, 4 : 1, 5 : 1})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52583eac",
   "metadata": {
    "id": "52583eac"
   },
   "outputs": [],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6872a31",
   "metadata": {
    "id": "e6872a31"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d2bc2",
   "metadata": {
    "id": "e50d2bc2"
   },
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ffa46b",
   "metadata": {
    "id": "d2ffa46b"
   },
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c45a40",
   "metadata": {
    "id": "c3c45a40"
   },
   "outputs": [],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34393733",
   "metadata": {
    "id": "34393733"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "825f52f5",
   "metadata": {
    "id": "825f52f5"
   },
   "source": [
    "# Tree Wilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56acc46",
   "metadata": {
    "id": "b56acc46"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/Wilt%20Dataset.csv\"\n",
    "df = pd.read_csv(url, header = None)\n",
    "\n",
    "p = 5\n",
    "\n",
    "X = df.drop(0, axis=1)\n",
    "y = df[0]\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403a313",
   "metadata": {
    "id": "2403a313"
   },
   "outputs": [],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22206e9",
   "metadata": {
    "id": "a22206e9"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee27f48",
   "metadata": {
    "id": "6ee27f48"
   },
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f74648",
   "metadata": {
    "id": "e0f74648"
   },
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d04b1b",
   "metadata": {
    "id": "a6d04b1b"
   },
   "outputs": [],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328704e",
   "metadata": {
    "id": "a328704e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57935570",
   "metadata": {
    "id": "57935570"
   },
   "source": [
    "# Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530a6d7",
   "metadata": {
    "id": "b530a6d7"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/spambase.data\"\n",
    "df = pd.read_csv(url, header = None)\n",
    "\n",
    "p = 56\n",
    "\n",
    "X = df.drop(57, axis=1)\n",
    "y = df[57]\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecbbcb",
   "metadata": {
    "id": "cfecbbcb"
   },
   "outputs": [],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b16c40",
   "metadata": {
    "id": "41b16c40"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009c83c",
   "metadata": {
    "id": "5009c83c"
   },
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907de3d",
   "metadata": {
    "id": "e907de3d"
   },
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b37197",
   "metadata": {
    "id": "76b37197"
   },
   "outputs": [],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9099a20",
   "metadata": {
    "id": "f9099a20"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b232f588",
   "metadata": {
    "id": "b232f588"
   },
   "source": [
    "# default of credit card clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6e97a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1692130525923,
     "user": {
      "displayName": "Max Chen",
      "userId": "09776589487161533265"
     },
     "user_tz": 300
    },
    "id": "cf6e97a6",
    "outputId": "9dd98b79-8890-47dc-911c-5091f9a40d24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23364\n",
       "1     6636\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/default%20of%20credit%20card%20clients.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "p = 23\n",
    "\n",
    "X = df.drop(\"Y\", axis=1)\n",
    "y = df[\"Y\"]\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122410a0",
   "metadata": {
    "id": "122410a0"
   },
   "outputs": [],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f90fb",
   "metadata": {
    "id": "e67f90fb"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7db398",
   "metadata": {
    "id": "6c7db398"
   },
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773a8f3",
   "metadata": {
    "id": "1773a8f3"
   },
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b860d",
   "metadata": {
    "id": "fd0b860d"
   },
   "outputs": [],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c441c851",
   "metadata": {
    "id": "c441c851"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a1149e1",
   "metadata": {
    "id": "3a1149e1"
   },
   "source": [
    "# APS Failure at Scania Trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13151a",
   "metadata": {
    "id": "8e13151a"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/aps_failure_test_set.csv\"\n",
    "# Read the training dataset from CSV\n",
    "train_df = pd.read_csv(url, na_values = 'na')\n",
    "\n",
    "p = 170\n",
    "\n",
    "# Read the test dataset from CSV\n",
    "test_df = pd.read_csv(url, na_values = 'na')\n",
    "\n",
    "# Add a 'Label' column to the test dataset and fill it with NaN values\n",
    "#test_df['Label'] = float('nan')\n",
    "\n",
    "# Concatenate the training and test datasets\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset to a new CSV file\n",
    "df.to_csv('combined.csv', index=False)\n",
    "\n",
    "missing_values_count = df.isna().sum()\n",
    "\n",
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]\n",
    "\n",
    "threshold = len(X) * 0.5\n",
    "X = X.dropna(thresh = threshold, axis = 1)\n",
    "\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "y = y.replace({\"neg\" : 0, \"pos\" : 1})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342feb5",
   "metadata": {
    "id": "1342feb5"
   },
   "outputs": [],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8025db",
   "metadata": {
    "id": "dc8025db"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e64b9",
   "metadata": {
    "id": "f12e64b9"
   },
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840c543",
   "metadata": {
    "id": "7840c543"
   },
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f551469",
   "metadata": {
    "id": "7f551469"
   },
   "outputs": [],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbb123",
   "metadata": {
    "id": "79dbb123"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97fe1aff",
   "metadata": {
    "id": "97fe1aff"
   },
   "source": [
    "# Epileptic Seizure Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce2301",
   "metadata": {
    "id": "4dce2301"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maxxxxc/SIR-Summer-2023/main/dataset/Epileptic%20Seizure%20Recognition.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "p = 178\n",
    "\n",
    "X = df.drop(\"y\", axis=1)\n",
    "y = df[\"y\"]\n",
    "\n",
    "X = X.drop(\"Unnamed\", axis=1)\n",
    "\n",
    "y = y.replace({4 : 0, 3 : 0, 2 : 0, 5 : 0})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90416fe3",
   "metadata": {
    "id": "90416fe3"
   },
   "outputs": [],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd044b1e",
   "metadata": {
    "id": "dd044b1e"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3b402",
   "metadata": {
    "id": "99f3b402"
   },
   "outputs": [],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572164b",
   "metadata": {
    "id": "2572164b"
   },
   "outputs": [],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cec944",
   "metadata": {
    "id": "f8cec944"
   },
   "outputs": [],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79a914",
   "metadata": {
    "id": "da79a914"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c1483be",
   "metadata": {
    "id": "0c1483be"
   },
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f273226",
   "metadata": {
    "id": "9f273226"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870c24e",
   "metadata": {
    "id": "7870c24e",
    "outputId": "2d218731-daec-4df4-b6fc-a9c3db16f78d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panda\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    6825\n",
       "1    6313\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Extract features (pixel values) and target labels\n",
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')\n",
    "\n",
    "p = 784\n",
    "\n",
    "label_counts = np.bincount(y)\n",
    "\n",
    "digit_filter = (y == 5) | (y == 8)\n",
    "X = X[digit_filter]\n",
    "y = y[digit_filter]\n",
    "\n",
    "np.unique(y)\n",
    "\n",
    "n5 = np.count_nonzero(y == 5)\n",
    "n8 = np.count_nonzero(y == 8)\n",
    "\n",
    "y = y.replace({5 : 1, 8 : 0})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412d984",
   "metadata": {
    "id": "c412d984",
    "outputId": "7398dc21-4594-4c25-b81f-25d2a2577ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [[0.         0.         0.         0.         0.         0.\n",
      "  0.98820396]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98439878]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98573059]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98649163]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98420852]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98287671]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98439878]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98535008]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98687215]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98687215]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98439878]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98515982]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98649163]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98192542]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98649163]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98306697]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98382801]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98420852]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98554033]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98649163]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98649163]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98668189]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98135464]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98458904]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98630137]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98344749]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98306697]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.9870624 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98401826]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98306697]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98573059]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98554033]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98744292]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98573059]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98687215]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98363775]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98573059]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98554033]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98573059]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.9870624 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98325723]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98573059]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98344749]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98496956]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.9870624 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.9847793 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98687215]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98649163]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98287671]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.98458904]]\n",
      "AUC: [[0.         0.         0.         0.         0.         0.\n",
      "  0.99952347]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99913378]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99908772]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99917694]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99921343]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99891926]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99920205]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.9990709 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99930984]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99919715]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99915959]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99928318]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99943899]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.998853  ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99909466]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99909742]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99911058]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99927518]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99930866]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99925266]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99924397]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99923992]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99881068]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99922853]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99925083]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99916653]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99899018]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99929677]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99918962]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99883762]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99923589]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99921575]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99947716]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99918405]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99940061]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99909666]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99916777]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99920553]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99919727]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99931713]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99915128]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99918375]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99917866]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99898526]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99940621]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99918095]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99921663]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99911427]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99924484]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.99917316]]\n"
     ]
    }
   ],
   "source": [
    "# Number of times to repeat the process\n",
    "num_repeats = 50\n",
    "\n",
    "# Initialize an empty matrix (10-by-4) to store accuracies\n",
    "accuracies = np.zeros((num_repeats, 7))\n",
    "auc_accuracies = np.zeros((num_repeats, 7))\n",
    "\n",
    "seed = 42\n",
    "# Repeat the process and store accuracies\n",
    "for i in range(num_repeats):\n",
    "    np.random.seed(seed)\n",
    "    accuracies[i], auc_accuracies[i] = svm_iterate_process(X, y)\n",
    "    seed += 2\n",
    "\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies:\", accuracies)\n",
    "print(\"AUC:\", auc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57be2bb",
   "metadata": {
    "id": "f57be2bb",
    "outputId": "1df61a3f-b71e-4687-922c-54b81911fb97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.98516362])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409ae97",
   "metadata": {
    "id": "8409ae97",
    "outputId": "48d12226-6d51-432d-daa0-cda90377ac8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00155896])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa1401",
   "metadata": {
    "id": "f1aa1401",
    "outputId": "0d02eec3-1b8c-4c01-d4ce-c685e640c12a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.99918592])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75281b",
   "metadata": {
    "id": "1d75281b",
    "outputId": "d4afaed5-54e7-4016-cbab-789be425115e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00014471])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(auc_accuracies, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4c42e",
   "metadata": {
    "id": "96a4c42e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
